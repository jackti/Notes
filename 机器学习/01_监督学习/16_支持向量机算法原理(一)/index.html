
<!doctype html>
<html lang="zh" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="采用Mkdocs-material生成的文档管理网站支持的markdown语法，包括传统语法和扩展语法">
      
      
      
      <link rel="icon" href="../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.3.0, mkdocs-material-8.2.9">
    
    
      
        <title>支持向量机算法原理(一) - 我的知识笔记</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.120efc48.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.9647289d.min.css">
        
          
          
          <meta name="theme-color" content="#2094f3">
        
      
    
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../../..",location),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="" data-md-color-primary="blue" data-md-color-accent="pink">
  
    
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#_1" class="md-skip">
          跳转至
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="页眉">
    <a href="../../.." title="我的知识笔记" class="md-header__button md-logo" aria-label="我的知识笔记" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            我的知识笔记
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              支持向量机算法原理(一)
            
          </span>
        </div>
      </div>
    </div>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="搜索" placeholder="搜索" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="查找">
        
        <button type="reset" class="md-search__icon md-icon" aria-label="清空当前内容" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            正在初始化搜索引擎
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="标签" data-md-component="tabs">
  <div class="md-tabs__inner md-grid">
    <ul class="md-tabs__list">
      
        
  
  


  <li class="md-tabs__item">
    <a href="../../.." class="md-tabs__link">
      首页
    </a>
  </li>

      
        
  
  
    
  


  
  
  
    

  
  
  
    <li class="md-tabs__item">
      <a href="../00_%E5%85%B6%E4%BB%96%E8%AE%B0%E5%BD%95/" class="md-tabs__link md-tabs__link--active">
        机器学习
      </a>
    </li>
  

  

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../../%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/00_%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/" class="md-tabs__link">
        深度学习
      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="导航栏" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="我的知识笔记" class="md-nav__button md-logo" aria-label="我的知识笔记" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    我的知识笔记
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../.." class="md-nav__link">
        首页
      </a>
    </li>
  

    
      
      
      

  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_2" type="checkbox" id="__nav_2" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_2">
          机器学习
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="机器学习" data-md-level="1">
        <label class="md-nav__title" for="__nav_2">
          <span class="md-nav__icon md-icon"></span>
          机器学习
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_2_1" type="checkbox" id="__nav_2_1" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_2_1">
          01 监督学习
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="01 监督学习" data-md-level="2">
        <label class="md-nav__title" for="__nav_2_1">
          <span class="md-nav__icon md-icon"></span>
          01 监督学习
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../00_%E5%85%B6%E4%BB%96%E8%AE%B0%E5%BD%95/" class="md-nav__link">
        数学符号
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../00_%E6%80%BB%E7%BB%93/" class="md-nav__link">
        线性模型
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../01_%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95/" class="md-nav__link">
        最小二乘法
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../02_%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E7%AE%97%E6%B3%95/" class="md-nav__link">
        梯度下降算法
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../03_%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81%E5%8E%9F%E7%90%86/" class="md-nav__link">
        交叉验证原理
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../04_%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/" class="md-nav__link">
        模型评估
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../05_%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86/" class="md-nav__link">
        线性回归算法原理
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../06_%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86/" class="md-nav__link">
        逻辑回归算法原理
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../07_%E5%86%B3%E7%AD%96%E6%A0%91%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86%28%E4%B8%80%29/" class="md-nav__link">
        决策树算法原理(一)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../08_%E5%86%B3%E7%AD%96%E6%A0%91%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86%28%E4%BA%8C%29/" class="md-nav__link">
        决策树算法原理(二)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../09_%E5%86%B3%E7%AD%96%E6%A0%91%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86%28%E4%B8%89%29/" class="md-nav__link">
        决策树算法原理(三)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../10_%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86/" class="md-nav__link">
        近邻算法原理
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../11_%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86/" class="md-nav__link">
        朴素贝叶斯算法原理
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../12_%E6%9C%80%E5%A4%A7%E7%86%B5%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86%28%E4%B8%80%29/" class="md-nav__link">
        最大熵算法原理(一)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../13_%E6%9C%80%E5%A4%A7%E7%86%B5%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86%28%E4%BA%8C%29/" class="md-nav__link">
        最大熵算法原理(二)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../14_%E6%9C%80%E5%A4%A7%E7%86%B5%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86%28%E4%B8%89%29/" class="md-nav__link">
        最大熵算法原理(三)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../15_%E6%84%9F%E7%9F%A5%E6%9C%BA%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86/" class="md-nav__link">
        感知机算法原理
      </a>
    </li>
  

            
          
            
              
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          支持向量机算法原理(一)
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        支持向量机算法原理(一)
      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#_2" class="md-nav__link">
    函数间隔和几何间隔
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_3" class="md-nav__link">
    感知机模型
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_4" class="md-nav__link">
    支持向量机模型
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_5" class="md-nav__link">
    支持向量机求解
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#svm" class="md-nav__link">
    线性可分SVM算法
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../17_%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86%28%E4%BA%8C%29/" class="md-nav__link">
        支持向量机算法原理(二)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../18_%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86%28%E4%B8%89%29/" class="md-nav__link">
        支持向量机算法原理(三)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../19_%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86%28%E5%9B%9B%29/" class="md-nav__link">
        支持向量机算法原理(四)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../20_%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86%28%E4%BA%94%29/" class="md-nav__link">
        支持向量机算法原理(五)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../21_%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E4%B9%8B%E7%BB%BC%E8%BF%B0/" class="md-nav__link">
        集成学习算法之综述
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../22_%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E4%B9%8BAdaboost/" class="md-nav__link">
        集成学习算法之Adaboost
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../23_%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E4%B9%8BRF/" class="md-nav__link">
        集成学习算法之RF
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../24_%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E4%B9%8BGBDT/" class="md-nav__link">
        集成学习算法之GBDT
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_2_2" type="checkbox" id="__nav_2_2" >
      
      
      
      
        <label class="md-nav__link" for="__nav_2_2">
          02 无监督学习
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="02 无监督学习" data-md-level="2">
        <label class="md-nav__title" for="__nav_2_2">
          <span class="md-nav__icon md-icon"></span>
          02 无监督学习
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../02_%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/25_%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95%E4%B9%8BK-Means/" class="md-nav__link">
        聚类算法之K-Means​
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../02_%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/26_%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95%E4%B9%8BBIRCH/" class="md-nav__link">
        聚类算法之BIRCH
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../02_%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/27_%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95%E4%B9%8BDBSCAN/" class="md-nav__link">
        聚类算法之DBSCAN
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../02_%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/28_%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95%E4%B9%8BMean%20Shift/" class="md-nav__link">
        聚类算法之Mean Shift
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../02_%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/29_%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95%E4%B9%8B%E8%B0%B1%E8%81%9A%E7%B1%BB/" class="md-nav__link">
        聚类算法之谱聚类
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../02_%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/30_%E9%99%8D%E7%BB%B4%E7%AE%97%E6%B3%95%E4%B9%8BPCA/" class="md-nav__link">
        降维算法之PCA
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../02_%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/31_%E9%99%8D%E7%BB%B4%E7%AE%97%E6%B3%95%E4%B9%8BLDA/" class="md-nav__link">
        降维算法之LDA
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../02_%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/32_%E9%99%8D%E7%BB%B4%E7%AE%97%E6%B3%95%E4%B9%8BIsomap/" class="md-nav__link">
        降维算法之Isomap
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../02_%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/33_%E9%99%8D%E7%BB%B4%E7%AE%97%E6%B3%95%E4%B9%8BLLE/" class="md-nav__link">
        降维算法之LLE
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../02_%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/34_%E5%85%B3%E8%81%94%E7%AE%97%E6%B3%95%E4%B9%8BApriori/" class="md-nav__link">
        关联算法之Apriori
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../02_%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/35_%E5%85%B3%E8%81%94%E7%AE%97%E6%B3%95%E4%B9%8BFP-Tree/" class="md-nav__link">
        关联算法之FP-Tree
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../02_%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/36_%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95%E4%B9%8B%E7%BB%BC%E8%BF%B0/" class="md-nav__link">
        推荐算法之综述
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../02_%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/37_%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95%E4%B9%8B%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3/" class="md-nav__link">
        推荐算法之矩阵分解
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../02_%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/38_%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95%E4%B9%8BSimRank/" class="md-nav__link">
        推荐算法之SimRank
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../02_%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/39_%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95%E4%B9%8BPersonalRank/" class="md-nav__link">
        推荐算法之PersonalRank
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../02_%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/40_EM%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86/" class="md-nav__link">
        EM算法原理
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../02_%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/41_%E5%88%86%E8%A7%A3%E6%9C%BA%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86/" class="md-nav__link">
        分解机算法原理
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3" type="checkbox" id="__nav_3" >
      
      
      
      
        <label class="md-nav__link" for="__nav_3">
          深度学习
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="深度学习" data-md-level="1">
        <label class="md-nav__title" for="__nav_3">
          <span class="md-nav__icon md-icon"></span>
          深度学习
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/00_%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/" class="md-nav__link">
        神经网络基础
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/01_DNN%E5%89%8D%E9%A6%88%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" class="md-nav__link">
        DNN前馈神经网络
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/02_CNN%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" class="md-nav__link">
        CNN卷积神经网络
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/03_RNN%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" class="md-nav__link">
        RNN循环神经网络
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/04_%E5%9F%BA%E4%BA%8E%E9%97%A8%E6%8E%A7%E7%9A%84%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" class="md-nav__link">
        基于门控的循环神经网络
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/05_%E7%BD%91%E7%BB%9C%E4%BC%98%E5%8C%96%281%29/" class="md-nav__link">
        神经网络优化概述
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/05_%E7%BD%91%E7%BB%9C%E4%BC%98%E5%8C%96%282%29/" class="md-nav__link">
        数据预处理
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/06_%E7%BD%91%E7%BB%9C%E6%AD%A3%E5%88%99%E5%8C%96/" class="md-nav__link">
        网络正则化
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/07_%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/" class="md-nav__link">
        07 注意力机制
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#_2" class="md-nav__link">
    函数间隔和几何间隔
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_3" class="md-nav__link">
    感知机模型
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_4" class="md-nav__link">
    支持向量机模型
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_5" class="md-nav__link">
    支持向量机求解
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#svm" class="md-nav__link">
    线性可分SVM算法
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content" data-md-component="content">
            <article class="md-content__inner md-typeset">
              
                


<h1 id="_1">支持向量机算法原理(一)<a class="headerlink" href="#_1" title="Permanent link">&para;</a></h1>
<p>支持向量机(Support Vector Machine,SVM)是一种二元分类模型，它的基础模型是定义在特征空间上的间隔最大的线性分类器，间隔最大使它有别于感知机模型；支持向量机还包括了核技巧，使得它能够处理非线性问题；支持向量机的学习策略就是间隔最大化，转化为一个求解凸二次规划的问题。经过改进和扩展，现在的支持向量机算法也可支持多分类问题和回归问题。</p>
<h2 id="_2">函数间隔和几何间隔<a class="headerlink" href="#_2" title="Permanent link">&para;</a></h2>
<p>在分离超平面固定<span class="arithmatex"><span class="MathJax_Preview">w^Tx+b=0</span><script type="math/tex">w^Tx+b=0</script></span>时候，<span class="arithmatex"><span class="MathJax_Preview">|w^Tx+b|</span><script type="math/tex">|w^Tx+b|</script></span>表示点<span class="arithmatex"><span class="MathJax_Preview">x</span><script type="math/tex">x</script></span>到超平面的距离。通过观察<span class="arithmatex"><span class="MathJax_Preview">w^Tx+b</span><script type="math/tex">w^Tx+b</script></span>与<span class="arithmatex"><span class="MathJax_Preview">y</span><script type="math/tex">y</script></span>是否同号来判断分类是否正确。定义函数间隔<span class="arithmatex"><span class="MathJax_Preview">\gamma^{'}</span><script type="math/tex">\gamma^{'}</script></span>：</p>
<div class="arithmatex">
<div class="MathJax_Preview">
\gamma^{’}=y(w^T x+b)
</div>
<script type="math/tex; mode=display">
\gamma^{’}=y(w^T x+b)
</script>
</div>
<p>可以看到，它就是感知机模型里面的误分类点到超平面距离的分子。函数间隔并不能反映点到超平面的距离。定义几何间隔：</p>
<div class="arithmatex">
<div class="MathJax_Preview">
\gamma =\frac{y(w^Tx+b)}{||w||_2}=\frac{\gamma^{'}}{||w||_2}
</div>
<script type="math/tex; mode=display">
\gamma =\frac{y(w^Tx+b)}{||w||_2}=\frac{\gamma^{'}}{||w||_2}
</script>
</div>
<p>几何间隔才是点到超平面的真正距离。感知机模型用到的距离就是几何距离。</p>
<h2 id="_3">感知机模型<a class="headerlink" href="#_3" title="Permanent link">&para;</a></h2>
<p>在二维平面中，感知机模型尝试找到一条直线，能够把二元数据隔离开。在三维或者更高的空间中，感知机模型能够找到一个超平面，将这个数据集中的二元类别数据隔离开。定义超平面为<span class="arithmatex"><span class="MathJax_Preview">w^T x+b=0</span><script type="math/tex">w^T x+b=0</script></span>，在超平面<span class="arithmatex"><span class="MathJax_Preview">w^T x+b=0</span><script type="math/tex">w^T x+b=0</script></span>上方的样例定义<span class="arithmatex"><span class="MathJax_Preview">y=1</span><script type="math/tex">y=1</script></span>，在超平面<span class="arithmatex"><span class="MathJax_Preview">w^Tx+b=0</span><script type="math/tex">w^Tx+b=0</script></span>下方的样例定义为<span class="arithmatex"><span class="MathJax_Preview">y=-1</span><script type="math/tex">y=-1</script></span>，满足这个条件的超平面存在多个，我们的目标是从这多个分离超平面中选择一个泛化能力最强的超平面。</p>
<p>感知机模型思想是让所有误分类点(定义为集合<span class="arithmatex"><span class="MathJax_Preview">M</span><script type="math/tex">M</script></span>)到超平面的距离和最小，其损失函数表达式如下：</p>
<div class="arithmatex">
<div class="MathJax_Preview">
\sum_{x_{i}\in M} \frac{-y^{(i)}(w^T x^{(i)}+b)}{||w||_2}
</div>
<script type="math/tex; mode=display">
\sum_{x_{i}\in M} \frac{-y^{(i)}(w^T x^{(i)}+b)}{||w||_2}
</script>
</div>
<p>分子和分母有固定的倍数关系，于是可以固定分子或者分母为1，然后求另一个即分子自己或者分母的导数的最小化损失函数。在感知机模型中采用保留分子，固定分子<span class="arithmatex"><span class="MathJax_Preview">||w||=1</span><script type="math/tex">||w||=1</script></span>，于是感知机模型的损失函数为：</p>
<div class="arithmatex">
<div class="MathJax_Preview">
\sum_{x^{(i)\in M}}-y^{(i)}(w^T x^{(i)}+b)
</div>
<script type="math/tex; mode=display">
\sum_{x^{(i)\in M}}-y^{(i)}(w^T x^{(i)}+b)
</script>
</div>
<p>在感知机模型中可以找到多个分类的超平面将数据分开，对于那些离超平面很远的点，让其离超平面更远没有意义，需要关注那些距离超平面很近的点，这些点是很容易被误分类的，要让这些比较近的点尽可能远离超平面，这样的分类效果会更好一些。</p>
<h2 id="_4">支持向量机模型<a class="headerlink" href="#_4" title="Permanent link">&para;</a></h2>
<p>假设超平面<span class="arithmatex"><span class="MathJax_Preview">(w,b)</span><script type="math/tex">(w,b)</script></span>能将训练样本正确分类，对<span class="arithmatex"><span class="MathJax_Preview">(x^{(i)},y^{(i)})\in D</span><script type="math/tex">(x^{(i)},y^{(i)})\in D</script></span>，如<span class="arithmatex"><span class="MathJax_Preview">y^{(i)}=+1</span><script type="math/tex">y^{(i)}=+1</script></span>，则有<span class="arithmatex"><span class="MathJax_Preview">w^Tx^{(i)}+b&gt;0</span><script type="math/tex">w^Tx^{(i)}+b>0</script></span>；若<span class="arithmatex"><span class="MathJax_Preview">y^{(i)}=-1</span><script type="math/tex">y^{(i)}=-1</script></span>，则有<span class="arithmatex"><span class="MathJax_Preview">w^Tx^{(i)}+b&lt;0</span><script type="math/tex">w^Tx^{(i)}+b<0</script></span>，令</p>
<div class="arithmatex">
<div class="MathJax_Preview">
\left \{
\begin{aligned}
    w^T x^{(i)}+b \ge +1,\qquad y^{(i)}=+1\\
    w^T x^{(i)}+b \lt -1,\qquad y^{(i)}=-1\\
\end{aligned}
\right.
</div>
<script type="math/tex; mode=display">
\left \{
\begin{aligned}
    w^T x^{(i)}+b \ge +1,\qquad y^{(i)}=+1\\
    w^T x^{(i)}+b \lt -1,\qquad y^{(i)}=-1\\
\end{aligned}
\right.
</script>
</div>
<p>距离超平面最近的几个训练样本点是上面的等号成立，他们被称为"支持向量"，两个异类支持向量<span class="arithmatex"><span class="MathJax_Preview">x^+,x^-</span><script type="math/tex">x^+,x^-</script></span>到超平面的距离之和<span class="arithmatex"><span class="MathJax_Preview">d</span><script type="math/tex">d</script></span>为：</p>
<div class="arithmatex">
<div class="MathJax_Preview">
\begin{align}
d &amp;= \frac{|w^T x^++b|}{||w||_2}+\frac{|w^T x^-+b|}{||w||_2}\\
&amp;=\frac{1}{||w||_2}( |w^Tx^++b|+|w^Tx^-+b|) \\
&amp;=\frac{1}{||w||_2}|(+1)-(-1)|\\
&amp; =\frac{2}{||w||_2}\\
\end{align}
</div>
<script type="math/tex; mode=display">
\begin{align}
d &= \frac{|w^T x^++b|}{||w||_2}+\frac{|w^T x^-+b|}{||w||_2}\\
&=\frac{1}{||w||_2}( |w^Tx^++b|+|w^Tx^-+b|) \\
&=\frac{1}{||w||_2}|(+1)-(-1)|\\
& =\frac{2}{||w||_2}\\
\end{align}
</script>
</div>
<p>公式(5)是利用点到距离的公式，计算两个异类支持向量的距离之和；公式(6)~(7)两支持向量分别过直线<span class="arithmatex"><span class="MathJax_Preview">w^Tx+b=+1</span><script type="math/tex">w^Tx+b=+1</script></span>和<span class="arithmatex"><span class="MathJax_Preview">w^T x+b=-1</span><script type="math/tex">w^T x+b=-1</script></span> ，将<span class="arithmatex"><span class="MathJax_Preview">\pm1</span><script type="math/tex">\pm1</script></span>带入。由于<span class="arithmatex"><span class="MathJax_Preview">\frac{2}{||w||_2}</span><script type="math/tex">\frac{2}{||w||_2}</script></span>最大化等价于<span class="arithmatex"><span class="MathJax_Preview">\frac{1}{2}||w||^2_2</span><script type="math/tex">\frac{1}{2}||w||^2_2</script></span>的最小化，这样支持向量机的基本型：</p>
<div class="arithmatex">
<div class="MathJax_Preview">
\begin{align}
                &amp;\min_{w,b}\frac{1}{2}||w||^2_2 \notag \\
                &amp; s.t. \quad y^{(i)}(w^T x^{i}+b)\ge 1,  \quad i=1,2,...,m
\end{align}
</div>
<script type="math/tex; mode=display">
\begin{align}
                &\min_{w,b}\frac{1}{2}||w||^2_2 \notag \\
                & s.t. \quad y^{(i)}(w^T x^{i}+b)\ge 1,  \quad i=1,2,...,m
\end{align}
</script>
</div>
<h2 id="_5">支持向量机求解<a class="headerlink" href="#_5" title="Permanent link">&para;</a></h2>
<p>由于目标函数<span class="arithmatex"><span class="MathJax_Preview">\frac{1}{2}||w||^2_2</span><script type="math/tex">\frac{1}{2}||w||^2_2</script></span>是凸函数，约束条件不等式是仿射的，根据凸优化理论，可以通过拉格朗日函数将优化目标转化为无约束的优化问题(和最大熵模型的优化方法一样)。具体地，对每一个不等式约束引进拉格朗日乘子，<span class="arithmatex"><span class="MathJax_Preview">\alpha_i \ge 0,i=1,2,...,m</span><script type="math/tex">\alpha_i \ge 0,i=1,2,...,m</script></span>，定义拉格朗日函数：</p>
<div class="arithmatex">
<div class="MathJax_Preview">
L(w,b,\alpha)=\frac{1}{2}||w||^2_2-\sum_{i=1}^{m}\alpha_i[ y^{(i)}(w^T x^{(i)}+b) -1 ]
</div>
<script type="math/tex; mode=display">
L(w,b,\alpha)=\frac{1}{2}||w||^2_2-\sum_{i=1}^{m}\alpha_i[ y^{(i)}(w^T x^{(i)}+b) -1 ]
</script>
</div>
<p>由于引入了拉格朗日乘子<span class="arithmatex"><span class="MathJax_Preview">\alpha=(\alpha_1,\alpha_1,...,\alpha_m)^T</span><script type="math/tex">\alpha=(\alpha_1,\alpha_1,...,\alpha_m)^T</script></span>，优化目标变成：</p>
<div class="arithmatex">
<div class="MathJax_Preview">
\min_{w,b} \max_{\alpha} L(w,b,\alpha)
</div>
<script type="math/tex; mode=display">
\min_{w,b} \max_{\alpha} L(w,b,\alpha)
</script>
</div>
<p>根据拉格朗日对偶性，原始问题的对偶问题是极大极小问题：</p>
<div class="arithmatex">
<div class="MathJax_Preview">
\max_\alpha \min_{w,b}L(w,b,\alpha)
</div>
<script type="math/tex; mode=display">
\max_\alpha \min_{w,b}L(w,b,\alpha)
</script>
</div>
<p>可以首先优化函数对于<span class="arithmatex"><span class="MathJax_Preview">w</span><script type="math/tex">w</script></span>和<span class="arithmatex"><span class="MathJax_Preview">b</span><script type="math/tex">b</script></span>的极小值，然后对拉格朗日乘子<span class="arithmatex"><span class="MathJax_Preview">\alpha</span><script type="math/tex">\alpha</script></span>的极大值。</p>
<p><strong>（1）求<span class="arithmatex"><span class="MathJax_Preview">\min_{w,b}L(w,b,\alpha)</span><script type="math/tex">\min_{w,b}L(w,b,\alpha)</script></span></strong></p>
<p>将拉格朗日函数<span class="arithmatex"><span class="MathJax_Preview">L(w,b,\alpha)</span><script type="math/tex">L(w,b,\alpha)</script></span>分别对<span class="arithmatex"><span class="MathJax_Preview">w</span><script type="math/tex">w</script></span>和<span class="arithmatex"><span class="MathJax_Preview">b</span><script type="math/tex">b</script></span>求偏导数并令其等于0。</p>
<div class="arithmatex">
<div class="MathJax_Preview">
\begin{align}
&amp;\nabla_w L \overset{def}= \frac{\partial L}{\partial w}=w-\sum_{i=1}^{m}\alpha_i y^{(i)}x^{(i)}=0\\
&amp;\nabla_b L \overset{def}= \frac{\partial L}{\partial b}=-\sum_{i=1}^{m}\alpha_i y^{(i)}=0\\
\end{align}
</div>
<script type="math/tex; mode=display">
\begin{align}
&\nabla_w L \overset{def}= \frac{\partial L}{\partial w}=w-\sum_{i=1}^{m}\alpha_i y^{(i)}x^{(i)}=0\\
&\nabla_b L \overset{def}= \frac{\partial L}{\partial b}=-\sum_{i=1}^{m}\alpha_i y^{(i)}=0\\
\end{align}
</script>
</div>
<p>得到：</p>
<div class="arithmatex">
<div class="MathJax_Preview">
\begin{align}
&amp; w=\sum_{i=1}^{m}\alpha_i y^{(i)}x^{(i)}\\
&amp; \sum_{i=1}^m \alpha_i y^{(i)}=0
\end{align}
</div>
<script type="math/tex; mode=display">
\begin{align}
& w=\sum_{i=1}^{m}\alpha_i y^{(i)}x^{(i)}\\
& \sum_{i=1}^m \alpha_i y^{(i)}=0
\end{align}
</script>
</div>
<p>从上面的式子中，可以得到<span class="arithmatex"><span class="MathJax_Preview">w</span><script type="math/tex">w</script></span>和<span class="arithmatex"><span class="MathJax_Preview">\alpha</span><script type="math/tex">\alpha</script></span>的关系。将<span class="arithmatex"><span class="MathJax_Preview">w</span><script type="math/tex">w</script></span>替换为<span class="arithmatex"><span class="MathJax_Preview">\alpha</span><script type="math/tex">\alpha</script></span>的表达式后的优化函数<span class="arithmatex"><span class="MathJax_Preview">\Psi(\alpha)</span><script type="math/tex">\Psi(\alpha)</script></span>的表达式：</p>
<div class="arithmatex">
<div class="MathJax_Preview">
\begin{align}
\Psi(\alpha)
&amp;=\frac{1}{2}||w||^2_2-\sum_{i=1}^{m}\alpha_i[ y^{(i)}(w^T x^{(i)}+b) -1 ]\\
&amp;=\frac{1}{2}w^T w-\sum_{i=1}^m\alpha_iy^{(i)}w^Tx^{(i)}-\sum_{i=1}^m\alpha_i y^{(i)}b+\sum_{i=1}^{m}\alpha_i\\
&amp;=\frac{1}{2}w^T  ( \sum_{i=1}^{m}\alpha_i y^{(i)}x^{(i)})-w^T \sum_{i=1}^m\alpha_iy^{(i)}x^{(i)}-\sum_{i=1}^m\alpha_i y^{(i)}b+\sum_{i=1}^{m}\alpha_i\\
&amp;=-\frac{1}{2}w^T  ( \sum_{i=1}^{m}\alpha_i y^{(i)}x^{(i)})-\sum_{i=1}^m\alpha_i y^{(i)}b+\sum_{i=1}^{m}\alpha_i\\
&amp;=-\frac{1}{2}(\sum_{i=1}^{m}\alpha_i y^{(i)}x^{(i)})^T  ( \sum_{i=1}^{m}\alpha_i y^{(i)}x^{(i)})-b\sum_{i=1}^m\alpha_i y^{(i)}+\sum_{i=1}^{m}\alpha_i\\
&amp;=-\frac{1}{2} \lgroup \sum_{i=1}^{m}\alpha_i y^{(i)}(x^{(i)})^T  \rgroup  \lgroup \sum_{i=1}^{m}\alpha_i y^{(i)}x^{(i)}\rgroup -b\sum_{i=1}^m\alpha_i y^{(i)}+\sum_{i=1}^{m}\alpha_i\\
&amp;=-\frac{1}{2}\lgroup \sum_{i=1}^{m}\alpha_i y^{(i)}(x^{(i)})^T \rgroup  \lgroup \sum_{i=1}^{m}\alpha_i y^{(i)}x^{(i)} \rgroup +\sum_{i=1}^{m}\alpha_i\\
&amp;=-\frac{1}{2}\sum_{i=1}^{m}\sum_{j=1}^m\lgroup \alpha_iy^{(i)}(x^{(i)})^T \alpha_jy^{(j)}x^{(j)}  \rgroup+\sum_{i=1}^m \alpha_i\\
&amp;=\sum_{i=1}^m \alpha_i-\frac{1}{2}\sum_{i=1,j=1}^m \alpha_i\alpha_jy^{(i)}y^{(j)}(x^{(i)})^T x^{(j)}
\end{align}
</div>
<script type="math/tex; mode=display">
\begin{align}
\Psi(\alpha)
&=\frac{1}{2}||w||^2_2-\sum_{i=1}^{m}\alpha_i[ y^{(i)}(w^T x^{(i)}+b) -1 ]\\
&=\frac{1}{2}w^T w-\sum_{i=1}^m\alpha_iy^{(i)}w^Tx^{(i)}-\sum_{i=1}^m\alpha_i y^{(i)}b+\sum_{i=1}^{m}\alpha_i\\
&=\frac{1}{2}w^T  ( \sum_{i=1}^{m}\alpha_i y^{(i)}x^{(i)})-w^T \sum_{i=1}^m\alpha_iy^{(i)}x^{(i)}-\sum_{i=1}^m\alpha_i y^{(i)}b+\sum_{i=1}^{m}\alpha_i\\
&=-\frac{1}{2}w^T  ( \sum_{i=1}^{m}\alpha_i y^{(i)}x^{(i)})-\sum_{i=1}^m\alpha_i y^{(i)}b+\sum_{i=1}^{m}\alpha_i\\
&=-\frac{1}{2}(\sum_{i=1}^{m}\alpha_i y^{(i)}x^{(i)})^T  ( \sum_{i=1}^{m}\alpha_i y^{(i)}x^{(i)})-b\sum_{i=1}^m\alpha_i y^{(i)}+\sum_{i=1}^{m}\alpha_i\\
&=-\frac{1}{2} \lgroup \sum_{i=1}^{m}\alpha_i y^{(i)}(x^{(i)})^T  \rgroup  \lgroup \sum_{i=1}^{m}\alpha_i y^{(i)}x^{(i)}\rgroup -b\sum_{i=1}^m\alpha_i y^{(i)}+\sum_{i=1}^{m}\alpha_i\\
&=-\frac{1}{2}\lgroup \sum_{i=1}^{m}\alpha_i y^{(i)}(x^{(i)})^T \rgroup  \lgroup \sum_{i=1}^{m}\alpha_i y^{(i)}x^{(i)} \rgroup +\sum_{i=1}^{m}\alpha_i\\
&=-\frac{1}{2}\sum_{i=1}^{m}\sum_{j=1}^m\lgroup \alpha_iy^{(i)}(x^{(i)})^T \alpha_jy^{(j)}x^{(j)}  \rgroup+\sum_{i=1}^m \alpha_i\\
&=\sum_{i=1}^m \alpha_i-\frac{1}{2}\sum_{i=1,j=1}^m \alpha_i\alpha_jy^{(i)}y^{(j)}(x^{(i)})^T x^{(j)}
\end{align}
</script>
</div>
<p>公式(17)<sub>(18)利用了范数的定义<span class="arithmatex"><span class="MathJax_Preview">||w||^2_2=w^T w</span><script type="math/tex">||w||^2_2=w^T w</script></span>；公式(18)-(22)使用了<span class="arithmatex"><span class="MathJax_Preview">w=\sum_{i=1}^m \alpha_iy^{(i)}x^{(i)}</span><script type="math/tex">w=\sum_{i=1}^m \alpha_iy^{(i)}x^{(i)}</script></span>合并同类项进行化简，由于常量的转置就是其本身，所以只有只有向量<span class="arithmatex"><span class="MathJax_Preview">x^{(i)}</span><script type="math/tex">x^{(i)}</script></span>被转置；公式(22)</sub>(23)利用了<span class="arithmatex"><span class="MathJax_Preview">\sum_{i=1}^m \alpha_i y^{(i)}=0</span><script type="math/tex">\sum_{i=1}^m \alpha_i y^{(i)}=0</script></span>；公式(23)~(24)利用：</p>
<div class="arithmatex">
<div class="MathJax_Preview">
\begin{aligned}
\sum_{i=1}^n x_i \cdot \sum_{i=1}^my_i
&amp;=(x_1+x_2+...+x_n)(y_1+y_2+...+y_n)\\
&amp;=(x_1y_1+x_1y_2+...x_1y_n)+(x_2y_1+x_2y_2+...+x_2y_n)+...+(x_ny_1+x_ny_2+...+x_ny_n)\\
&amp;=x_1y_1+x_1y_2+...x_1y_n+x_2y_1+x_2y_2+...+x_2y_n+...+x_ny_1+x_ny_2+...+x_ny_n\\
&amp;=\sum_{i=1,j=1}^m x_i y_j
\end{aligned}
</div>
<script type="math/tex; mode=display">
\begin{aligned}
\sum_{i=1}^n x_i \cdot \sum_{i=1}^my_i
&=(x_1+x_2+...+x_n)(y_1+y_2+...+y_n)\\
&=(x_1y_1+x_1y_2+...x_1y_n)+(x_2y_1+x_2y_2+...+x_2y_n)+...+(x_ny_1+x_ny_2+...+x_ny_n)\\
&=x_1y_1+x_1y_2+...x_1y_n+x_2y_1+x_2y_2+...+x_2y_n+...+x_ny_1+x_ny_2+...+x_ny_n\\
&=\sum_{i=1,j=1}^m x_i y_j
\end{aligned}
</script>
</div>
<p><strong>（2）求<span class="arithmatex"><span class="MathJax_Preview">\max_\limits{\alpha}\Psi(\alpha)</span><script type="math/tex">\max_\limits{\alpha}\Psi(\alpha)</script></span></strong> </p>
<p>从上面的推导，通过对<span class="arithmatex"><span class="MathJax_Preview">w,b</span><script type="math/tex">w,b</script></span>极小化以后，优化函数<span class="arithmatex"><span class="MathJax_Preview">\Psi(\alpha)</span><script type="math/tex">\Psi(\alpha)</script></span>仅仅只有向量<span class="arithmatex"><span class="MathJax_Preview">\alpha</span><script type="math/tex">\alpha</script></span>为参数，此时对<span class="arithmatex"><span class="MathJax_Preview">\Psi(\alpha)</span><script type="math/tex">\Psi(\alpha)</script></span>求极大化的数学表达式为：</p>
<div class="arithmatex">
<div class="MathJax_Preview">
\begin{align}
&amp;\max_\alpha -\frac{1}{2}\sum_{i=1}^m\sum_{j=1}^m\alpha_i \alpha_jy^{(i)}y^{(j)}\left ( x^{(i)} \cdot x^{(j)} \right ) +\sum_{i=1}^m\alpha_i \\
&amp;s.t. \quad \sum_{i=1}^m \alpha_i y^{(i)}=0 \notag \\
&amp;\alpha_i \ge 0  ,\quad i =1,2,...,m  \notag
\end{align}
</div>
<script type="math/tex; mode=display">
\begin{align}
&\max_\alpha -\frac{1}{2}\sum_{i=1}^m\sum_{j=1}^m\alpha_i \alpha_jy^{(i)}y^{(j)}\left ( x^{(i)} \cdot x^{(j)} \right ) +\sum_{i=1}^m\alpha_i \\
&s.t. \quad \sum_{i=1}^m \alpha_i y^{(i)}=0 \notag \\
&\alpha_i \ge 0  ,\quad i =1,2,...,m  \notag
\end{align}
</script>
</div>
<p>等价的极小化问题如下：</p>
<div class="arithmatex">
<div class="MathJax_Preview">
\begin{align}
&amp;\min_\alpha \frac{1}{2}\sum_{i=1}^m\sum_{j=1}^m\alpha_i \alpha_jy^{(i)}y^{(j)}\left ( x^{(i)} \cdot x^{(j)} \right ) -\sum_{i=1}^m\alpha_i \\
&amp;s.t. \quad \sum_{i=1}^m \alpha_i y^{(i)}=0 \notag \\
&amp;\alpha_i \ge 0  ,\quad i =1,2,...,m  \notag
\end{align}
</div>
<script type="math/tex; mode=display">
\begin{align}
&\min_\alpha \frac{1}{2}\sum_{i=1}^m\sum_{j=1}^m\alpha_i \alpha_jy^{(i)}y^{(j)}\left ( x^{(i)} \cdot x^{(j)} \right ) -\sum_{i=1}^m\alpha_i \\
&s.t. \quad \sum_{i=1}^m \alpha_i y^{(i)}=0 \notag \\
&\alpha_i \ge 0  ,\quad i =1,2,...,m  \notag
\end{align}
</script>
</div>
<p>这是一个关于<span class="arithmatex"><span class="MathJax_Preview">\alpha</span><script type="math/tex">\alpha</script></span>向量的二次规划问题，可以使用通用的的二次规划算法来求解。然而，该问题的规模正比于训练样本数，在求解过程中开销很大。因此利用问题本身的特征，提出了很多高效算法如SMO算法。</p>
<p>假设通过SMO算法，得到了<span class="arithmatex"><span class="MathJax_Preview">\alpha</span><script type="math/tex">\alpha</script></span>的最优解为<span class="arithmatex"><span class="MathJax_Preview">\alpha^*=(\alpha_1^*,\alpha_2^*,...,\alpha_m^*)</span><script type="math/tex">\alpha^*=(\alpha_1^*,\alpha_2^*,...,\alpha_m^*)</script></span>，根据<span class="arithmatex"><span class="MathJax_Preview">w=\sum_{i=1}^m \alpha_i y^{(i)}x^{(i)}</span><script type="math/tex">w=\sum_{i=1}^m \alpha_i y^{(i)}x^{(i)}</script></span>，可得到对应的<span class="arithmatex"><span class="MathJax_Preview">w</span><script type="math/tex">w</script></span>的值：</p>
<div class="arithmatex">
<div class="MathJax_Preview">
w^* = \sum_{i=1}^m \alpha_i^* y^{(i)} x^{(i)}
</div>
<script type="math/tex; mode=display">
w^* = \sum_{i=1}^m \alpha_i^* y^{(i)} x^{(i)}
</script>
</div>
<p>对于**任意的支持向量**<span class="arithmatex"><span class="MathJax_Preview">(x^{s},y^{s})</span><script type="math/tex">(x^{s},y^{s})</script></span>，都有</p>
<div class="arithmatex">
<div class="MathJax_Preview">
\begin{align}
&amp; y^s(w^T x^s + b)=y^s( \sum_{i=1}^m \alpha_i y^{(i)}( x^{(i)})^T x^s+b)=1\\
\Rightarrow &amp;b = y^s-\sum_{i=1}^m \alpha_i y^{(i)}( x^{(i)})^T x^s
\end{align}
</div>
<script type="math/tex; mode=display">
\begin{align}
& y^s(w^T x^s + b)=y^s( \sum_{i=1}^m \alpha_i y^{(i)}( x^{(i)})^T x^s+b)=1\\
\Rightarrow &b = y^s-\sum_{i=1}^m \alpha_i y^{(i)}( x^{(i)})^T x^s
\end{align}
</script>
</div>
<p>如果有<span class="arithmatex"><span class="MathJax_Preview">S</span><script type="math/tex">S</script></span>个支持向量，则对应的可以求出<span class="arithmatex"><span class="MathJax_Preview">S</span><script type="math/tex">S</script></span>个<span class="arithmatex"><span class="MathJax_Preview">b^*</span><script type="math/tex">b^*</script></span>，理论上这<span class="arithmatex"><span class="MathJax_Preview">S</span><script type="math/tex">S</script></span>个<span class="arithmatex"><span class="MathJax_Preview">b^*</span><script type="math/tex">b^*</script></span>都可以作为最终的结果。这里采用一种更加健壮的办法，求出所有<span class="arithmatex"><span class="MathJax_Preview">S</span><script type="math/tex">S</script></span>个支持向量所对应的<span class="arithmatex"><span class="MathJax_Preview">b^*</span><script type="math/tex">b^*</script></span>，然后将其平均值作为最终的结果。(注：对于严格线性可分的SVM，<span class="arithmatex"><span class="MathJax_Preview">b</span><script type="math/tex">b</script></span>的值是有唯一解的，所有支持向量对应的<span class="arithmatex"><span class="MathJax_Preview">b^*</span><script type="math/tex">b^*</script></span>都是一样的，这里这么写是为了和后面加入软间隔SVM算法描述一致)</p>
<p>根据KKT条件中对偶互补条件<span class="arithmatex"><span class="MathJax_Preview">\alpha^*(y^{(i)}(w^T x^{(i)}+b)-1)=0</span><script type="math/tex">\alpha^*(y^{(i)}(w^T x^{(i)}+b)-1)=0</script></span>，如果<span class="arithmatex"><span class="MathJax_Preview">a_i^*&gt;0</span><script type="math/tex">a_i^*>0</script></span>则有<span class="arithmatex"><span class="MathJax_Preview">y^{(i)}(w^T x^{(i)}+b)=1</span><script type="math/tex">y^{(i)}(w^T x^{(i)}+b)=1</script></span>即该点是支持向量，如果<span class="arithmatex"><span class="MathJax_Preview">a_i^*=0</span><script type="math/tex">a_i^*=0</script></span>则有<span class="arithmatex"><span class="MathJax_Preview">y^{(i)}(w^T x^{(i)}+b)\gt 1</span><script type="math/tex">y^{(i)}(w^T x^{(i)}+b)\gt 1</script></span>即该点已经被正确分类。</p>
<h2 id="svm">线性可分SVM算法<a class="headerlink" href="#svm" title="Permanent link">&para;</a></h2>
<blockquote>
<p>输入：线性可分数据集<span class="arithmatex"><span class="MathJax_Preview">D=\{(x^{(1)},y^{(i)}),(x^{(2)},y^{(2)}),...,(x^{(m)},y^{(m)})\}</span><script type="math/tex">D=\{(x^{(1)},y^{(i)}),(x^{(2)},y^{(2)}),...,(x^{(m)},y^{(m)})\}</script></span>,其中<span class="arithmatex"><span class="MathJax_Preview">x^{(i)}\in \mathbb{R}^n,y^{(i)}\in\{+1,-1\}</span><script type="math/tex">x^{(i)}\in \mathbb{R}^n,y^{(i)}\in\{+1,-1\}</script></span></p>
<p>输出：分离超平面和分类决策函数</p>
<p>(1)构造约束优化问题</p>
<div class="arithmatex">
<div class="MathJax_Preview">
\begin{aligned}
&amp;\min_\alpha \frac{1}{2}\sum_{i=1}^m\sum_{j=1}^m\alpha_i \alpha_jy^{(i)}y^{(j)}\left ( x^{(i)} \cdot x^{(j)} \right ) -\sum_{i=1}^m\alpha_i \\
&amp;s.t. \quad \sum_{i=1}^m \alpha_i y^{(i)}=0 \notag \\
&amp;\alpha_i \ge 0  ,\quad i =1,2,...,m  \notag
\end{aligned}
</div>
<script type="math/tex; mode=display">
\begin{aligned}
&\min_\alpha \frac{1}{2}\sum_{i=1}^m\sum_{j=1}^m\alpha_i \alpha_jy^{(i)}y^{(j)}\left ( x^{(i)} \cdot x^{(j)} \right ) -\sum_{i=1}^m\alpha_i \\
&s.t. \quad \sum_{i=1}^m \alpha_i y^{(i)}=0 \notag \\
&\alpha_i \ge 0  ,\quad i =1,2,...,m  \notag
\end{aligned}
</script>
</div>
<p>(2)利用二次规划优化算法或者SMO算法得到最优解<span class="arithmatex"><span class="MathJax_Preview">\alpha^*=(\alpha_1^*,\alpha_2^*,...,\alpha_m^*)</span><script type="math/tex">\alpha^*=(\alpha_1^*,\alpha_2^*,...,\alpha_m^*)</script></span> </p>
<p>(3)计算<span class="arithmatex"><span class="MathJax_Preview">w^*=\sum_{i=1}^m \alpha_i^* y^{(i)} x^{(i)}</span><script type="math/tex">w^*=\sum_{i=1}^m \alpha_i^* y^{(i)} x^{(i)}</script></span></p>
<p>(4)找出所有的<span class="arithmatex"><span class="MathJax_Preview">S</span><script type="math/tex">S</script></span>个支持向量即<span class="arithmatex"><span class="MathJax_Preview">\alpha_i \gt 0</span><script type="math/tex">\alpha_i \gt 0</script></span>所对应的点<span class="arithmatex"><span class="MathJax_Preview">(x^s,y^s)</span><script type="math/tex">(x^s,y^s)</script></span>，计算每个点对应的<span class="arithmatex"><span class="MathJax_Preview">b^s = y^s-\sum_{i=1}^m \alpha_i y^{(i)}( x^{(i)})^T x^s</span><script type="math/tex">b^s = y^s-\sum_{i=1}^m \alpha_i y^{(i)}( x^{(i)})^T x^s</script></span> ，对所有的<span class="arithmatex"><span class="MathJax_Preview">b^s</span><script type="math/tex">b^s</script></span>求和取平均值得到<span class="arithmatex"><span class="MathJax_Preview">b^*=\frac{1}{S}\sum_{i=1}^Sb^s</span><script type="math/tex">b^*=\frac{1}{S}\sum_{i=1}^Sb^s</script></span></p>
<p>(5)求分离超平面为<span class="arithmatex"><span class="MathJax_Preview">w^*\cdot x + b^*=0</span><script type="math/tex">w^*\cdot x + b^*=0</script></span>，分类决策函数为<span class="arithmatex"><span class="MathJax_Preview">f(x)=sign(w^*\cdot x +b^*)</span><script type="math/tex">f(x)=sign(w^*\cdot x +b^*)</script></span> </p>
</blockquote>

              
            </article>
          </div>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
    <nav class="md-footer__inner md-grid" aria-label="页脚">
      
        
        <a href="../15_%E6%84%9F%E7%9F%A5%E6%9C%BA%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86/" class="md-footer__link md-footer__link--prev" aria-label="上一页: 感知机算法原理" rel="prev">
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
          </div>
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                上一页
              </span>
              感知机算法原理
            </div>
          </div>
        </a>
      
      
        
        <a href="../17_%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86%28%E4%BA%8C%29/" class="md-footer__link md-footer__link--next" aria-label="下一页: 支持向量机算法原理(二)" rel="next">
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                下一页
              </span>
              支持向量机算法原理(二)
            </div>
          </div>
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4Z"/></svg>
          </div>
        </a>
      
    </nav>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    <script id="__config" type="application/json">{"base": "../../..", "features": ["navigation.tabs"], "search": "../../../assets/javascripts/workers/search.2a1c317c.min.js", "translations": {"clipboard.copied": "\u5df2\u590d\u5236", "clipboard.copy": "\u590d\u5236", "search.config.lang": "ja", "search.config.pipeline": "trimmer, stemmer", "search.config.separator": "[\\uff0c\\u3002]+", "search.placeholder": "\u641c\u7d22", "search.result.more.one": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.other": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 # \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.term.missing": "\u7f3a\u5c11", "select.version.title": "\u9009\u62e9\u5f53\u524d\u7248\u672c"}}</script>
    
    
      <script src="../../../assets/javascripts/bundle.6e54b5cd.min.js"></script>
      
        <script src="../../../javascript/config.js"></script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML"></script>
      
    
  </body>
</html>