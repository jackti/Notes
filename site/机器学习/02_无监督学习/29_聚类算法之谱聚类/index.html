
<!doctype html>
<html lang="zh" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="采用Mkdocs-material生成的文档管理网站支持的markdown语法，包括传统语法和扩展语法">
      
      
      
      <link rel="icon" href="../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.3.0, mkdocs-material-8.2.9">
    
    
      
        <title>聚类算法之谱聚类 - 我的知识笔记</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.120efc48.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.9647289d.min.css">
        
          
          
          <meta name="theme-color" content="#2094f3">
        
      
    
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../../..",location),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="" data-md-color-primary="blue" data-md-color-accent="pink">
  
    
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#_1" class="md-skip">
          跳转至
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="页眉">
    <a href="../../.." title="我的知识笔记" class="md-header__button md-logo" aria-label="我的知识笔记" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            我的知识笔记
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              聚类算法之谱聚类
            
          </span>
        </div>
      </div>
    </div>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="搜索" placeholder="搜索" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="查找">
        
        <button type="reset" class="md-search__icon md-icon" aria-label="清空当前内容" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            正在初始化搜索引擎
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="标签" data-md-component="tabs">
  <div class="md-tabs__inner md-grid">
    <ul class="md-tabs__list">
      
        
  
  


  <li class="md-tabs__item">
    <a href="../../.." class="md-tabs__link">
      首页
    </a>
  </li>

      
        
  
  
    
  


  
  
  
    

  
  
  
    <li class="md-tabs__item">
      <a href="../../01_%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/00_%E5%85%B6%E4%BB%96%E8%AE%B0%E5%BD%95/" class="md-tabs__link md-tabs__link--active">
        机器学习
      </a>
    </li>
  

  

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../../%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/00_%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/" class="md-tabs__link">
        深度学习
      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="导航栏" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="我的知识笔记" class="md-nav__button md-logo" aria-label="我的知识笔记" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    我的知识笔记
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../.." class="md-nav__link">
        首页
      </a>
    </li>
  

    
      
      
      

  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_2" type="checkbox" id="__nav_2" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_2">
          机器学习
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="机器学习" data-md-level="1">
        <label class="md-nav__title" for="__nav_2">
          <span class="md-nav__icon md-icon"></span>
          机器学习
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_2_1" type="checkbox" id="__nav_2_1" >
      
      
      
      
        <label class="md-nav__link" for="__nav_2_1">
          01 监督学习
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="01 监督学习" data-md-level="2">
        <label class="md-nav__title" for="__nav_2_1">
          <span class="md-nav__icon md-icon"></span>
          01 监督学习
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../01_%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/00_%E5%85%B6%E4%BB%96%E8%AE%B0%E5%BD%95/" class="md-nav__link">
        数学符号
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../01_%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/00_%E6%80%BB%E7%BB%93/" class="md-nav__link">
        线性模型
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../01_%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/01_%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95/" class="md-nav__link">
        最小二乘法
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../01_%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/02_%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E7%AE%97%E6%B3%95/" class="md-nav__link">
        梯度下降算法
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../01_%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/03_%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81%E5%8E%9F%E7%90%86/" class="md-nav__link">
        交叉验证原理
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../01_%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/04_%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/" class="md-nav__link">
        模型评估
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../01_%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/05_%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86/" class="md-nav__link">
        线性回归算法原理
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../01_%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/06_%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86/" class="md-nav__link">
        逻辑回归算法原理
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../01_%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/07_%E5%86%B3%E7%AD%96%E6%A0%91%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86%28%E4%B8%80%29/" class="md-nav__link">
        决策树算法原理(一)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../01_%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/08_%E5%86%B3%E7%AD%96%E6%A0%91%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86%28%E4%BA%8C%29/" class="md-nav__link">
        决策树算法原理(二)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../01_%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/09_%E5%86%B3%E7%AD%96%E6%A0%91%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86%28%E4%B8%89%29/" class="md-nav__link">
        决策树算法原理(三)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../01_%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/10_%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86/" class="md-nav__link">
        近邻算法原理
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../01_%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/11_%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86/" class="md-nav__link">
        朴素贝叶斯算法原理
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../01_%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/12_%E6%9C%80%E5%A4%A7%E7%86%B5%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86%28%E4%B8%80%29/" class="md-nav__link">
        最大熵算法原理(一)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../01_%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/13_%E6%9C%80%E5%A4%A7%E7%86%B5%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86%28%E4%BA%8C%29/" class="md-nav__link">
        最大熵算法原理(二)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../01_%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/14_%E6%9C%80%E5%A4%A7%E7%86%B5%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86%28%E4%B8%89%29/" class="md-nav__link">
        最大熵算法原理(三)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../01_%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/15_%E6%84%9F%E7%9F%A5%E6%9C%BA%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86/" class="md-nav__link">
        感知机算法原理
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../01_%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/16_%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86%28%E4%B8%80%29/" class="md-nav__link">
        支持向量机算法原理(一)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../01_%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/17_%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86%28%E4%BA%8C%29/" class="md-nav__link">
        支持向量机算法原理(二)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../01_%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/18_%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86%28%E4%B8%89%29/" class="md-nav__link">
        支持向量机算法原理(三)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../01_%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/19_%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86%28%E5%9B%9B%29/" class="md-nav__link">
        支持向量机算法原理(四)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../01_%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/20_%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86%28%E4%BA%94%29/" class="md-nav__link">
        支持向量机算法原理(五)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../01_%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/21_%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E4%B9%8B%E7%BB%BC%E8%BF%B0/" class="md-nav__link">
        集成学习算法之综述
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../01_%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/22_%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E4%B9%8BAdaboost/" class="md-nav__link">
        集成学习算法之Adaboost
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../01_%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/23_%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E4%B9%8BRF/" class="md-nav__link">
        集成学习算法之RF
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../01_%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/24_%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E4%B9%8BGBDT/" class="md-nav__link">
        集成学习算法之GBDT
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_2_2" type="checkbox" id="__nav_2_2" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_2_2">
          02 无监督学习
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="02 无监督学习" data-md-level="2">
        <label class="md-nav__title" for="__nav_2_2">
          <span class="md-nav__icon md-icon"></span>
          02 无监督学习
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../25_%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95%E4%B9%8BK-Means/" class="md-nav__link">
        聚类算法之K-Means​
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../26_%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95%E4%B9%8BBIRCH/" class="md-nav__link">
        聚类算法之BIRCH
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../27_%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95%E4%B9%8BDBSCAN/" class="md-nav__link">
        聚类算法之DBSCAN
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../28_%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95%E4%B9%8BMean%20Shift/" class="md-nav__link">
        聚类算法之Mean Shift
      </a>
    </li>
  

            
          
            
              
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          聚类算法之谱聚类
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        聚类算法之谱聚类
      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#_2" class="md-nav__link">
    谱聚类基础之一：无向权重图
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_3" class="md-nav__link">
    谱聚类基础之二：相似矩阵
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_4" class="md-nav__link">
    谱聚类基础之三：拉普拉斯矩阵
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_5" class="md-nav__link">
    谱聚类基础之四：无向图切图
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_6" class="md-nav__link">
    谱聚类之切图聚类
  </a>
  
    <nav class="md-nav" aria-label="谱聚类之切图聚类">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ratiocut" class="md-nav__link">
    RatioCut切图
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ncut" class="md-nav__link">
    NCut切图
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_7" class="md-nav__link">
    谱聚类总结
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../30_%E9%99%8D%E7%BB%B4%E7%AE%97%E6%B3%95%E4%B9%8BPCA/" class="md-nav__link">
        降维算法之PCA
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../31_%E9%99%8D%E7%BB%B4%E7%AE%97%E6%B3%95%E4%B9%8BLDA/" class="md-nav__link">
        降维算法之LDA
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../32_%E9%99%8D%E7%BB%B4%E7%AE%97%E6%B3%95%E4%B9%8BIsomap/" class="md-nav__link">
        降维算法之Isomap
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../33_%E9%99%8D%E7%BB%B4%E7%AE%97%E6%B3%95%E4%B9%8BLLE/" class="md-nav__link">
        降维算法之LLE
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../34_%E5%85%B3%E8%81%94%E7%AE%97%E6%B3%95%E4%B9%8BApriori/" class="md-nav__link">
        关联算法之Apriori
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../35_%E5%85%B3%E8%81%94%E7%AE%97%E6%B3%95%E4%B9%8BFP-Tree/" class="md-nav__link">
        关联算法之FP-Tree
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../36_%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95%E4%B9%8B%E7%BB%BC%E8%BF%B0/" class="md-nav__link">
        推荐算法之综述
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../37_%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95%E4%B9%8B%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3/" class="md-nav__link">
        推荐算法之矩阵分解
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../38_%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95%E4%B9%8BSimRank/" class="md-nav__link">
        推荐算法之SimRank
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../39_%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95%E4%B9%8BPersonalRank/" class="md-nav__link">
        推荐算法之PersonalRank
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../40_EM%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86/" class="md-nav__link">
        EM算法原理
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../41_%E5%88%86%E8%A7%A3%E6%9C%BA%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86/" class="md-nav__link">
        分解机算法原理
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3" type="checkbox" id="__nav_3" >
      
      
      
      
        <label class="md-nav__link" for="__nav_3">
          深度学习
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="深度学习" data-md-level="1">
        <label class="md-nav__title" for="__nav_3">
          <span class="md-nav__icon md-icon"></span>
          深度学习
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/00_%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/" class="md-nav__link">
        神经网络基础
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/01_DNN%E5%89%8D%E9%A6%88%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" class="md-nav__link">
        DNN前馈神经网络
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/02_CNN%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" class="md-nav__link">
        CNN卷积神经网络
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/03_RNN%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" class="md-nav__link">
        RNN循环神经网络
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/04_%E5%9F%BA%E4%BA%8E%E9%97%A8%E6%8E%A7%E7%9A%84%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" class="md-nav__link">
        基于门控的循环神经网络
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/05_%E7%BD%91%E7%BB%9C%E4%BC%98%E5%8C%96%281%29/" class="md-nav__link">
        神经网络优化概述
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/05_%E7%BD%91%E7%BB%9C%E4%BC%98%E5%8C%96%282%29/" class="md-nav__link">
        数据预处理
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/06_%E7%BD%91%E7%BB%9C%E6%AD%A3%E5%88%99%E5%8C%96/" class="md-nav__link">
        网络正则化
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/07_%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/" class="md-nav__link">
        07 注意力机制
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#_2" class="md-nav__link">
    谱聚类基础之一：无向权重图
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_3" class="md-nav__link">
    谱聚类基础之二：相似矩阵
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_4" class="md-nav__link">
    谱聚类基础之三：拉普拉斯矩阵
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_5" class="md-nav__link">
    谱聚类基础之四：无向图切图
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_6" class="md-nav__link">
    谱聚类之切图聚类
  </a>
  
    <nav class="md-nav" aria-label="谱聚类之切图聚类">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ratiocut" class="md-nav__link">
    RatioCut切图
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ncut" class="md-nav__link">
    NCut切图
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_7" class="md-nav__link">
    谱聚类总结
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content" data-md-component="content">
            <article class="md-content__inner md-typeset">
              
                


<h1 id="_1">聚类算法之谱聚类<a class="headerlink" href="#_1" title="Permanent link">&para;</a></h1>
<p>谱聚类(Spectral Clustering)是广泛应用的聚类算法，比起传统的K-Means算法，谱聚类对数据分布的适应性强，聚类效果也很好且聚类的计算量小很多。在处理实际问题时，谱聚类可以作为首先考虑的算法之一。</p>
<p>谱聚类是从图论中演化过来的，主要思想是把所有的数据看做空间中点，这些点之间可以用边连接起来。距离较远的两个点之间的边权重值较低，而距离较近的两个点之间的边权重较高。通过对所有数据点组成的图进行切图，让切图后不同的子图间边权重尽可能的低，而子图的边权重和尽可能的高，从而达到聚类的目的。</p>
<h2 id="_2">谱聚类基础之一：无向权重图<a class="headerlink" href="#_2" title="Permanent link">&para;</a></h2>
<p>对于一个图<span class="arithmatex"><span class="MathJax_Preview">G</span><script type="math/tex">G</script></span>，一般用点集合<span class="arithmatex"><span class="MathJax_Preview">V</span><script type="math/tex">V</script></span>和边集合<span class="arithmatex"><span class="MathJax_Preview">E</span><script type="math/tex">E</script></span>来描述，记作<span class="arithmatex"><span class="MathJax_Preview">G(V,E)</span><script type="math/tex">G(V,E)</script></span>。其中<span class="arithmatex"><span class="MathJax_Preview">V</span><script type="math/tex">V</script></span>包含了数据集中所有的点<span class="arithmatex"><span class="MathJax_Preview">(v_1,v_2,...,v_n)</span><script type="math/tex">(v_1,v_2,...,v_n)</script></span>，对于<span class="arithmatex"><span class="MathJax_Preview">V</span><script type="math/tex">V</script></span>中任意两个点，可以有边连接，也可以没有边连接，定义点<span class="arithmatex"><span class="MathJax_Preview">v_i</span><script type="math/tex">v_i</script></span>和<span class="arithmatex"><span class="MathJax_Preview">v_j</span><script type="math/tex">v_j</script></span>之间的权重为<span class="arithmatex"><span class="MathJax_Preview">w_{ij}</span><script type="math/tex">w_{ij}</script></span>。</p>
<p>对于有边连接的两个点<span class="arithmatex"><span class="MathJax_Preview">v_i</span><script type="math/tex">v_i</script></span>和<span class="arithmatex"><span class="MathJax_Preview">v_j</span><script type="math/tex">v_j</script></span>，权重<span class="arithmatex"><span class="MathJax_Preview">w_{ij}&gt;0</span><script type="math/tex">w_{ij}>0</script></span>；对于没有边连接的两个点<span class="arithmatex"><span class="MathJax_Preview">v_i</span><script type="math/tex">v_i</script></span>和<span class="arithmatex"><span class="MathJax_Preview">v_j</span><script type="math/tex">v_j</script></span>，权重<span class="arithmatex"><span class="MathJax_Preview">w_{ij}=0</span><script type="math/tex">w_{ij}=0</script></span>。</p>
<p>利用所有点之间的权重图，可以得到一个图的邻接矩阵<span class="arithmatex"><span class="MathJax_Preview">W</span><script type="math/tex">W</script></span>，是一个<span class="arithmatex"><span class="MathJax_Preview">n\times n</span><script type="math/tex">n\times n</script></span>的矩阵，第<span class="arithmatex"><span class="MathJax_Preview">i</span><script type="math/tex">i</script></span>行的第<span class="arithmatex"><span class="MathJax_Preview">j</span><script type="math/tex">j</script></span>个值对应了权重<span class="arithmatex"><span class="MathJax_Preview">w_{ij}</span><script type="math/tex">w_{ij}</script></span>
$$
W=\left(
\begin{matrix}
w_{11} &amp; w_{12}  &amp;...&amp;w_{1n} \
w_{21} &amp; w_{22}  &amp;...&amp;w_{2n} \
\vdots &amp;\vdots  &amp;\vdots&amp;\vdots \
w_{n1} &amp; w_{n2}  &amp;...&amp;w_{nn} \
\end{matrix}
\right)\notag
$$
对于图中的任意一个点<span class="arithmatex"><span class="MathJax_Preview">v_i</span><script type="math/tex">v_i</script></span>，它的度<span class="arithmatex"><span class="MathJax_Preview">d_i</span><script type="math/tex">d_i</script></span>定义为所有和它相连的边权重之和，即
$$
d_i=\sum_{j=1}^n w_{ij}
$$
利用每个点度的定义，可以得到一个<span class="arithmatex"><span class="MathJax_Preview">n\times n</span><script type="math/tex">n\times n</script></span>的对角矩阵<span class="arithmatex"><span class="MathJax_Preview">D</span><script type="math/tex">D</script></span>，只有对角线有值，对应第<span class="arithmatex"><span class="MathJax_Preview">i</span><script type="math/tex">i</script></span>行的第<span class="arithmatex"><span class="MathJax_Preview">i</span><script type="math/tex">i</script></span>个点度数，即
$$
D=\left(
\begin{matrix}
d_1 &amp;0  &amp;...&amp;0 \
0 &amp;d_2  &amp;...&amp;0 \
\vdots &amp;\vdots  &amp;\vdots&amp;\vdots \
0 &amp; 0  &amp;...&amp;d_n \
\end{matrix}
\right)\notag
$$
此外还有两个符号定义：<span class="arithmatex"><span class="MathJax_Preview">|A|</span><script type="math/tex">|A|</script></span>表示集合<span class="arithmatex"><span class="MathJax_Preview">A</span><script type="math/tex">A</script></span>中点的个数，<span class="arithmatex"><span class="MathJax_Preview">vol(A):=\sum_\limits{i\in A} d_i</span><script type="math/tex">vol(A):=\sum_\limits{i\in A} d_i</script></span>表示集合<span class="arithmatex"><span class="MathJax_Preview">A</span><script type="math/tex">A</script></span>中所有点的度之和。</p>
<h2 id="_3">谱聚类基础之二：相似矩阵<a class="headerlink" href="#_3" title="Permanent link">&para;</a></h2>
<p>邻接矩阵<span class="arithmatex"><span class="MathJax_Preview">W</span><script type="math/tex">W</script></span>由任意两点之间的权重值<span class="arithmatex"><span class="MathJax_Preview">w_{ij}</span><script type="math/tex">w_{ij}</script></span>组成。而<span class="arithmatex"><span class="MathJax_Preview">w_{ij}</span><script type="math/tex">w_{ij}</script></span>的取值一般满足距离较远的两个点之间的边权重较低，距离较近的两个点之间的边权重较高。通常构建邻接矩阵的<span class="arithmatex"><span class="MathJax_Preview">W</span><script type="math/tex">W</script></span>的方法有三类：<span class="arithmatex"><span class="MathJax_Preview">\epsilon-</span><script type="math/tex">\epsilon-</script></span>近邻法、<span class="arithmatex"><span class="MathJax_Preview">k</span><script type="math/tex">k</script></span>近邻法和全连接法。</p>
<p><strong><span class="arithmatex"><span class="MathJax_Preview">\epsilon-</span><script type="math/tex">\epsilon-</script></span>近邻法</strong></p>
<p>首先利用欧式距离<span class="arithmatex"><span class="MathJax_Preview">s_{ij}</span><script type="math/tex">s_{ij}</script></span>度量任意两个点<span class="arithmatex"><span class="MathJax_Preview">x_i</span><script type="math/tex">x_i</script></span>和<span class="arithmatex"><span class="MathJax_Preview">x_j</span><script type="math/tex">x_j</script></span>的距离，设置一个距离阈值<span class="arithmatex"><span class="MathJax_Preview">\epsilon</span><script type="math/tex">\epsilon</script></span>，然后根据<span class="arithmatex"><span class="MathJax_Preview">s_{ij}</span><script type="math/tex">s_{ij}</script></span>和<span class="arithmatex"><span class="MathJax_Preview">\epsilon</span><script type="math/tex">\epsilon</script></span>的大小关系定义邻接矩阵<span class="arithmatex"><span class="MathJax_Preview">W</span><script type="math/tex">W</script></span>如下：
$$
W_{ij}=
\left{
\begin{array}{}
0  \qquad s_{ij}\gt \epsilon \
\epsilon  \qquad s_{ij}\le \epsilon
\end{array}</p>
<p>\right.
$$
从式(2)可以看出两点之间的权重不是<span class="arithmatex"><span class="MathJax_Preview">\epsilon</span><script type="math/tex">\epsilon</script></span>就是0，没有其他的信息了。距离远近的度量不是很精确，因此使用较少。</p>
<p><strong><span class="arithmatex"><span class="MathJax_Preview">k</span><script type="math/tex">k</script></span>近邻法</strong></p>
<p>利用KNN算法遍历所有的样本点，取每个样本最近的<span class="arithmatex"><span class="MathJax_Preview">k</span><script type="math/tex">k</script></span>个点作为近邻，只有和样本距离最近的<span class="arithmatex"><span class="MathJax_Preview">k</span><script type="math/tex">k</script></span>个点之间的<span class="arithmatex"><span class="MathJax_Preview">w_{ij}\gt 0</span><script type="math/tex">w_{ij}\gt 0</script></span>但是这样的方法会导致邻接矩阵<span class="arithmatex"><span class="MathJax_Preview">W</span><script type="math/tex">W</script></span>非对称。为了解决这个问题，通常采用下面两种方法之一：</p>
<p>第一种<span class="arithmatex"><span class="MathJax_Preview">k</span><script type="math/tex">k</script></span>近邻是只要一点在另一点的<span class="arithmatex"><span class="MathJax_Preview">k</span><script type="math/tex">k</script></span>近邻中，则保留<span class="arithmatex"><span class="MathJax_Preview">s_{ij}</span><script type="math/tex">s_{ij}</script></span>
$$
W_{ij}=W_{ji}=\left{
    \begin{matrix}
    0 &amp; x^{(i)}\notin KNN(x^{(j)}) \; and \; x^{(j)}\notin KNN(x^{(i)})  \
    \exp(-\frac{||x<sup>{(i)}-x</sup>{(j)}||<sup>2}{2\sigma</sup>2}) &amp; x^{(i)}\in KNN(x^{(j)}) \; or \; x^{(j)}\in KNN(x^{(i)}) 
    \end{matrix}
\right.
$$
第二种<span class="arithmatex"><span class="MathJax_Preview">k</span><script type="math/tex">k</script></span>近邻是必须两点互为<span class="arithmatex"><span class="MathJax_Preview">k</span><script type="math/tex">k</script></span>近邻，才能保留<span class="arithmatex"><span class="MathJax_Preview">s_{ij}</span><script type="math/tex">s_{ij}</script></span>
$$
W_{ij}=W_{ji}=\left{
    \begin{matrix}
    0 &amp; x^{(i)}\notin KNN(x^{(j)}) \; or \; x^{(j)}\notin KNN(x^{(i)})  \
    \exp(-\frac{||x<sup>{(i)}-x</sup>{(j)}||<sup>2}{2\sigma</sup>2}) &amp; x^{(i)}\in KNN(x^{(j)}) \; and \; x^{(j)}\in KNN(x^{(i)}) 
    \end{matrix}
\right.
$$</p>
<p><strong>全连接</strong></p>
<p>全连接的方法中所有的点之间的权重都大于0，可以选择不同的核函数来定义边权重，常用的有多项式核函数，高斯核函数和Sigmoid核函数。常用的是高斯核函数RBF：
$$
W_{ij}=\exp(-\frac{||x<sup>{(i)}-x</sup>{(j)}||_2<sup>2}{2\sigma</sup>2})
$$
在实际应用中，使用全连接的方法来建立邻接矩阵最普遍。</p>
<h2 id="_4">谱聚类基础之三：拉普拉斯矩阵<a class="headerlink" href="#_4" title="Permanent link">&para;</a></h2>
<p>定义拉普拉斯矩阵<span class="arithmatex"><span class="MathJax_Preview">L=D-W</span><script type="math/tex">L=D-W</script></span>，其中<span class="arithmatex"><span class="MathJax_Preview">D</span><script type="math/tex">D</script></span>为度矩阵，是一个对角矩阵，<span class="arithmatex"><span class="MathJax_Preview">W</span><script type="math/tex">W</script></span>是邻接矩阵。</p>
<p>拉普拉斯矩阵具有的性质：</p>
<p>（1）拉普拉斯矩阵是对称的，因为<span class="arithmatex"><span class="MathJax_Preview">W</span><script type="math/tex">W</script></span>和<span class="arithmatex"><span class="MathJax_Preview">D</span><script type="math/tex">D</script></span>都是对称矩阵；</p>
<p>（2）由于拉普拉斯矩阵是对称矩阵，则它所有特征值都是实数；</p>
<p>（3）对于任意向量<span class="arithmatex"><span class="MathJax_Preview">f</span><script type="math/tex">f</script></span>，都有
$$
\begin{align}
f^T L f
&amp;=f^T(D-W)f\
&amp;=f^T Df -f^TWf\
&amp;=\sum_{i=1}^n d_i f_i<sup>2-\sum_{i=1,j=1}</sup>nw_{ij}f_if_j\
&amp;=\frac{1}{2}(\sum_{i=1}^n d_i f_i<sup>2-2\sum_{i=1,j=1}</sup>nw_{ij}f_if_j+\sum_{j=1}^n d_j f_j^2)\
&amp;=\frac{1}{2}\sum_{i=1,j=1}^n w_{ij}(f_i-f_j)^2
\end{align}
$$
（4）拉普拉斯矩阵是正定的，且对应的<span class="arithmatex"><span class="MathJax_Preview">n</span><script type="math/tex">n</script></span>个实数特征值都大于等于0，即<span class="arithmatex"><span class="MathJax_Preview">0=\lambda_1\le\lambda_2\le...\le\lambda_n</span><script type="math/tex">0=\lambda_1\le\lambda_2\le...\le\lambda_n</script></span>，且最小的特征值为0</p>
<h2 id="_5">谱聚类基础之四：无向图切图<a class="headerlink" href="#_5" title="Permanent link">&para;</a></h2>
<p>对于无向图<span class="arithmatex"><span class="MathJax_Preview">G(V,E)</span><script type="math/tex">G(V,E)</script></span>，切分为互相没有连接的<span class="arithmatex"><span class="MathJax_Preview">k</span><script type="math/tex">k</script></span>个子图，每个子图的集合为<span class="arithmatex"><span class="MathJax_Preview">A_1,A_2,...,A_k</span><script type="math/tex">A_1,A_2,...,A_k</script></span>，满足<span class="arithmatex"><span class="MathJax_Preview">A_i\cap A_j=\empty</span><script type="math/tex">A_i\cap A_j=\empty</script></span>，且<span class="arithmatex"><span class="MathJax_Preview">A_1\cup A_2\cup...\cup A_k=V</span><script type="math/tex">A_1\cup A_2\cup...\cup A_k=V</script></span>。</p>
<p>对于任意两个子图点的集合<span class="arithmatex"><span class="MathJax_Preview">A,B\in V,A\cap B=\empty</span><script type="math/tex">A,B\in V,A\cap B=\empty</script></span>，于是定义<span class="arithmatex"><span class="MathJax_Preview">A</span><script type="math/tex">A</script></span>和<span class="arithmatex"><span class="MathJax_Preview">B</span><script type="math/tex">B</script></span>之间的切图权重为：
$$
W(A,B)=\sum_{i\in A,j\in B}w_{ij}
$$
对于<span class="arithmatex"><span class="MathJax_Preview">k</span><script type="math/tex">k</script></span>个子图点的集合：<span class="arithmatex"><span class="MathJax_Preview">A_1,A_2,...,A_k</span><script type="math/tex">A_1,A_2,...,A_k</script></span>，定义切图cut为：
$$
cut(A_1,A_2,...,A_k)=\frac{1}{2}\sum_{i=1}^k W(A_i,\bar{A}_i)
$$
其中<span class="arithmatex"><span class="MathJax_Preview">\bar{A}_i</span><script type="math/tex">\bar{A}_i</script></span>为<span class="arithmatex"><span class="MathJax_Preview">A_i</span><script type="math/tex">A_i</script></span>的补集。</p>
<p>由于切图的目的是使得每个子图内部结构相似，这个相似表现为连边的权重平均都较大，且互相连接，而每个子图间则尽量没有边相连，或者连边的权重很低，所以优化目标可以表述为：
$$
\min cut(A_1,A_2,...,A_k)=\min\frac{1}{2}\sum_{i=1}^k W(A_i,\bar{A}_i)
$$
但是很容易发现这种极小化的切图存在问题，如下图</p>
<p><img alt="cut" src="../assets/cut.jpg" /></p>
<p>为了最小化<span class="arithmatex"><span class="MathJax_Preview">cut(A_1,A_2,...,A_k)</span><script type="math/tex">cut(A_1,A_2,...,A_k)</script></span>，需要选择C和H之间进行cut，但是却不是最优的切图。</p>
<h2 id="_6">谱聚类之切图聚类<a class="headerlink" href="#_6" title="Permanent link">&para;</a></h2>
<p>为了避免最小切图导致的切图效果不佳，需要对每个子图的规模做出限制。一般来说，有两种切图方式，风别是RatioCut和Ncut。</p>
<h3 id="ratiocut">RatioCut切图<a class="headerlink" href="#ratiocut" title="Permanent link">&para;</a></h3>
<p>对每个切图，不仅考虑最小化<span class="arithmatex"><span class="MathJax_Preview">cut(A_1,A_2,...,A_k)</span><script type="math/tex">cut(A_1,A_2,...,A_k)</script></span>，同时还要考虑最大化每个子图的个数即：
$$
RatioCut(A_1,A_2,...,A_k)=\frac{1}{2}\sum_{i=1}^k \frac{W(A_i,\bar{A}<em>i)}{|A_i|}
$$
为了最小化这个<span class="arithmatex"><span class="MathJax_Preview">RationCut(\cdot)</span><script type="math/tex">RationCut(\cdot)</script></span>函数，引入指示向量<span class="arithmatex"><span class="MathJax_Preview">\{h_1,h_2,...,h_j,...,h_k\},j=1,2,...,k</span><script type="math/tex">\{h_1,h_2,...,h_j,...,h_k\},j=1,2,...,k</script></span>，对于任意向量<span class="arithmatex"><span class="MathJax_Preview">h_j\in \mathbb{R}^n</span><script type="math/tex">h_j\in \mathbb{R}^n</script></span>，这里<span class="arithmatex"><span class="MathJax_Preview">n</span><script type="math/tex">n</script></span>是样本数
$$
h</em>{ji}=\left{
    \begin{aligned}
    &amp;0 &amp; v_i \notin A_j\
    &amp;\frac{1}{\sqrt{|A_j|}}&amp; v_i \in A_j
    \end{aligned}
\right.
$$
现在考虑<span class="arithmatex"><span class="MathJax_Preview">h_i^T L h_i</span><script type="math/tex">h_i^T L h_i</script></span>有：
$$
\begin{align}
h_i^T L h_i
&amp;=\frac{1}{2}\sum_{m=1}\sum_{n=1}w_{mn}(h_{im}-h_{in})^2\
&amp;=\frac{1}{2}(\sum_{m\in A_i,n\notin A_i}w_{mn}(\frac{1}{\sqrt{|A_{i}|}}-0)^2
+\sum_{m\notin A_i,n\in A_i}w_{mn}(0-\frac{1}{\sqrt{|A_{i}|}})^2)\
&amp;=\frac{1}{2}(\sum_{m\in A_i,n\notin A_i}w_{mn}\frac{1}{|A_i|} + \sum_{m\notin A_i,n\in A_i}w_{mn}\frac{1}{|A_i|})\
&amp;=\frac{1}{2}(cut(A_i,\bar{A}_i)\frac{1}{|A_i|}+cut(\bar{A}_i,A_i)\frac{1}{|A_i|})\
&amp;=\frac{cut(A_i,\bar{A}_i)}{|A_i|}\
&amp;=RationCut(A_i,\bar{A}_i)
\end{align}
$$
公式(15)利用了拉普拉斯矩阵的性质；</p>
<p>公式(15)~(17)主要利用<span class="arithmatex"><span class="MathJax_Preview">m,n</span><script type="math/tex">m,n</script></span>是否属于<span class="arithmatex"><span class="MathJax_Preview">A_i</span><script type="math/tex">A_i</script></span>有四中情况：</p>
<p>①<span class="arithmatex"><span class="MathJax_Preview">m\in A_i \; n\in A_i</span><script type="math/tex">m\in A_i \; n\in A_i</script></span> 这时候<span class="arithmatex"><span class="MathJax_Preview">h_{im}=h_{in}=\frac{1}{\sqrt{|A_j|}}</span><script type="math/tex">h_{im}=h_{in}=\frac{1}{\sqrt{|A_j|}}</script></span></p>
<p>②<span class="arithmatex"><span class="MathJax_Preview">m\notin A_i \; n\in A_i</span><script type="math/tex">m\notin A_i \; n\in A_i</script></span> 这时候<span class="arithmatex"><span class="MathJax_Preview">h_{im}=0\quad h_{in}=\frac{1}{\sqrt{|A_j|}}</span><script type="math/tex">h_{im}=0\quad h_{in}=\frac{1}{\sqrt{|A_j|}}</script></span></p>
<p>③<span class="arithmatex"><span class="MathJax_Preview">m\in A_i \; n\notin A_i</span><script type="math/tex">m\in A_i \; n\notin A_i</script></span> 这时候<span class="arithmatex"><span class="MathJax_Preview">h_{im}=\frac{1}{\sqrt{|A_j|}} \quad h_{in}=0</span><script type="math/tex">h_{im}=\frac{1}{\sqrt{|A_j|}} \quad h_{in}=0</script></span></p>
<p>④<span class="arithmatex"><span class="MathJax_Preview">m\notin A_i \; n\notin A_i</span><script type="math/tex">m\notin A_i \; n\notin A_i</script></span> 这时候<span class="arithmatex"><span class="MathJax_Preview">h_{im}= h_{in}=0</span><script type="math/tex">h_{im}= h_{in}=0</script></span></p>
<p>公式(17)~(19)利用<span class="arithmatex"><span class="MathJax_Preview">cut(\cdot)</span><script type="math/tex">cut(\cdot)</script></span>的定义，且<span class="arithmatex"><span class="MathJax_Preview">cut(A_i,\bar{A}_i)=cut(\bar{A}_i,A_i)</span><script type="math/tex">cut(A_i,\bar{A}_i)=cut(\bar{A}_i,A_i)</script></span>。</p>
<p>所以最终式(14)可以等价于：
$$
RatioCut(A_1,A_2,...,A_k)=\sum_{i=1}^k h_i^T L h_i = \sum_{i=1}<sup>k(H</sup>TL H)<em>{ii}=tr(H^TLH)
$$
其中<span class="arithmatex"><span class="MathJax_Preview">tr(H^TLH)</span><script type="math/tex">tr(H^TLH)</script></span>为矩阵的迹。优化目标可以写成：
$$
\arg \min</em>{H} tr(H^T L H) \quad s.t. \quad H^TH=I
$$
由于<span class="arithmatex"><span class="MathJax_Preview">H</span><script type="math/tex">H</script></span>矩阵里面的每一个指示向量都是<span class="arithmatex"><span class="MathJax_Preview">n</span><script type="math/tex">n</script></span>维的，向量中每个变量的取值为0或者<span class="arithmatex"><span class="MathJax_Preview">\frac{1}{\sqrt{|A_j|}}</span><script type="math/tex">\frac{1}{\sqrt{|A_j|}}</script></span>，就有<span class="arithmatex"><span class="MathJax_Preview">2^n</span><script type="math/tex">2^n</script></span>中取值，有<span class="arithmatex"><span class="MathJax_Preview">k</span><script type="math/tex">k</script></span>个子图就有<span class="arithmatex"><span class="MathJax_Preview">k</span><script type="math/tex">k</script></span>个指示向量，共计<span class="arithmatex"><span class="MathJax_Preview">k2^n</span><script type="math/tex">k2^n</script></span>中可能取值的<span class="arithmatex"><span class="MathJax_Preview">H</span><script type="math/tex">H</script></span>。这是一个NP难的问题。</p>
<p>但是观察发现<span class="arithmatex"><span class="MathJax_Preview">tr(H^TLH)</span><script type="math/tex">tr(H^TLH)</script></span>中的每一个优化子目标<span class="arithmatex"><span class="MathJax_Preview">h_i^T L h_i</span><script type="math/tex">h_i^T L h_i</script></span>，其中<span class="arithmatex"><span class="MathJax_Preview">h</span><script type="math/tex">h</script></span>是单位正交基，<span class="arithmatex"><span class="MathJax_Preview">L</span><script type="math/tex">L</script></span>是对称矩阵，此时<span class="arithmatex"><span class="MathJax_Preview">h_i^T L h_i</span><script type="math/tex">h_i^T L h_i</script></span>的最大值为<span class="arithmatex"><span class="MathJax_Preview">L</span><script type="math/tex">L</script></span>的最大特征值，最小值是<span class="arithmatex"><span class="MathJax_Preview">L</span><script type="math/tex">L</script></span>的最小特征值。</p>
<p>对于<span class="arithmatex"><span class="MathJax_Preview">h_i^T L h_i</span><script type="math/tex">h_i^T L h_i</script></span>，目标是找到最小的<span class="arithmatex"><span class="MathJax_Preview">L</span><script type="math/tex">L</script></span>的特征值，而<span class="arithmatex"><span class="MathJax_Preview">tr(H<sup>TLH)=\sum_{i=1}</sup>k h_i^T L h_i <span class="arithmatex"><span class="MathJax_Preview">的优化目标就是找到</span><script type="math/tex">的优化目标就是找到</script></span>kk</span><script type="math/tex">tr(H<sup>TLH)=\sum_{i=1}</sup>k h_i^T L h_i <span class="arithmatex"><span class="MathJax_Preview">的优化目标就是找到</span><script type="math/tex">的优化目标就是找到</script></span>kk</script></span>个最小的特征值，一般而言<span class="arithmatex"><span class="MathJax_Preview">k</span><script type="math/tex">k</script></span>是远远小于<span class="arithmatex"><span class="MathJax_Preview">n</span><script type="math/tex">n</script></span>，从而近似解决了这个NP难的问题。</p>
<p>通过找到<span class="arithmatex"><span class="MathJax_Preview">L</span><script type="math/tex">L</script></span>的最小<span class="arithmatex"><span class="MathJax_Preview">k</span><script type="math/tex">k</script></span>个特征值，可以得到对应的<span class="arithmatex"><span class="MathJax_Preview">k</span><script type="math/tex">k</script></span>个特征向量，这<span class="arithmatex"><span class="MathJax_Preview">k</span><script type="math/tex">k</script></span>个特征向量组成一个<span class="arithmatex"><span class="MathJax_Preview">n\times k</span><script type="math/tex">n\times k</script></span>的矩阵，即<span class="arithmatex"><span class="MathJax_Preview">H</span><script type="math/tex">H</script></span>。一般需要对<span class="arithmatex"><span class="MathJax_Preview">H</span><script type="math/tex">H</script></span>矩阵按行做标准化，即
$$
h_{ij}<sup>*=\frac{h_{ij}}{\sqrt{\sum_{t=1}</sup>k h_{it}^2}}
$$
由于在使用维度规约的时候损失了少量信息，得到的优化后指示向量<span class="arithmatex"><span class="MathJax_Preview">h</span><script type="math/tex">h</script></span>对应的<span class="arithmatex"><span class="MathJax_Preview">H</span><script type="math/tex">H</script></span>现在不能完全指示各样本所属类别，因此一般在得到<span class="arithmatex"><span class="MathJax_Preview">n\times k</span><script type="math/tex">n\times k</script></span>维度的矩阵<span class="arithmatex"><span class="MathJax_Preview">H</span><script type="math/tex">H</script></span>后还需要对每一行进行依次传统的聚类，如K-Means聚类等。</p>
<h3 id="ncut">NCut切图<a class="headerlink" href="#ncut" title="Permanent link">&para;</a></h3>
<p>NCut切图和RatioCut切图类似，只是将RatioCut中分母<span class="arithmatex"><span class="MathJax_Preview">|A_i|</span><script type="math/tex">|A_i|</script></span>换成了<span class="arithmatex"><span class="MathJax_Preview">vol(A_i)</span><script type="math/tex">vol(A_i)</script></span>。由于子图样本的个数多并不一定权重就大，所以基于权重的切图更加符合目标。因此一般而言NCut切图是优于RatioCut切图的。
$$
NCut(A_1,A_2,...,A_k)=\frac{1}{2}\sum_{i=1}^k\frac{W(A_i,\bar{A}<em>i)}{vol(A_i)}
$$
NCut切图对指示向量<span class="arithmatex"><span class="MathJax_Preview">h</span><script type="math/tex">h</script></span>做了改进，定义如下：
$$
h</em>{ji}=\left{
    \begin{aligned}
    &amp;0 &amp; v_i \notin A_j\
    &amp;\frac{1}{\sqrt{vol(A_j)}}&amp; v_i \in A_j
    \end{aligned}
\right.
$$
对于<span class="arithmatex"><span class="MathJax_Preview">h_i^T L h_i</span><script type="math/tex">h_i^T L h_i</script></span>有：
$$
\begin{align}
h_i^T L h_i
&amp;=\frac{1}{2}\sum_{m=1}\sum_{n=1}w_{mn}(h_{im}-h_{in})^2\
&amp;=\frac{1}{2}(\sum_{m\in A_i,n\notin A_i}w_{mn}(\frac{1}{\sqrt{vol(A_{i})}}-0)^2
+\sum_{m\notin A_i,n\in A_i}w_{mn}(0-\frac{1}{\sqrt{vol(A_{i})}})^2)\
&amp;=\frac{1}{2}(\sum_{m\in A_i,n\notin A_i}w_{mn}\frac{1}{vol(A_{i})} + \sum_{m\notin A_i,n\in A_i}w_{mn}\frac{1}{vol(A_{i})})\
&amp;=\frac{1}{2}(cut(A_i,\bar{A}<em>i)\frac{1}{vol(A</em>{i})}+cut(\bar{A}<em>i,A_i)\frac{1}{vol(A</em>{i})})\
&amp;=\frac{cut(A_i,\bar{A}<em>i)}{vol(A</em>{i})}\
&amp;=RationCut(A_i,\bar{A}<em>i)
\end{align}
$$
推导方式和RatioCut完全一致，优化目标为：
$$
NCut(A_1,A_2,...A_k) = \sum\limits</em>{i=1}<sup>{k}h_i</sup>TLh_i = \sum\limits_{i=1}<sup>{k}(H</sup>TLH)<em>{ii} = tr(H^TLH)
$$
此时<span class="arithmatex"><span class="MathJax_Preview">H^TH\ne I</span><script type="math/tex">H^TH\ne I</script></span>，但是<span class="arithmatex"><span class="MathJax_Preview">H^TDH=I</span><script type="math/tex">H^TDH=I</script></span>，推导如下：
$$
h_i^TDh_i = \sum\limits</em>{j=1}<sup>{n}h_{ij}</sup>2d_j =\frac{1}{vol(A_i)}\sum\limits_{v_j \in A_i}w_{v_j} = \frac{1}{vol(A_i)}vol(A_i) =1
$$
最终的优化目标为：
$$
\arg \min_{H} tr(H^T L H) \quad s.t. \quad H^TDH=I
$$
此时<span class="arithmatex"><span class="MathJax_Preview">H</span><script type="math/tex">H</script></span>中的指示向量<span class="arithmatex"><span class="MathJax_Preview">h</span><script type="math/tex">h</script></span>并不是标准正交基，所以需要将<span class="arithmatex"><span class="MathJax_Preview">H</span><script type="math/tex">H</script></span>进行小小的转化，令<span class="arithmatex"><span class="MathJax_Preview">H=D^{-1/2}F</span><script type="math/tex">H=D^{-1/2}F</script></span>，则式(33)转化为：
$$
\arg \min_{F} tr(F^T D<sup>{-&frac12;}LD</sup>{-&frac12;}F) \quad s.t. \quad F^TF=I
$$
式(34)和RatioCut基本一致了，只是中间的<span class="arithmatex"><span class="MathJax_Preview">L</span><script type="math/tex">L</script></span>变成了<span class="arithmatex"><span class="MathJax_Preview">D^{-1/2}LD^{-1/2}</span><script type="math/tex">D^{-1/2}LD^{-1/2}</script></span>，可以求出<span class="arithmatex"><span class="MathJax_Preview">D^{-1/2}LD^{-1/2}</span><script type="math/tex">D^{-1/2}LD^{-1/2}</script></span>的最小的前<span class="arithmatex"><span class="MathJax_Preview">k</span><script type="math/tex">k</script></span>个特征值，然后求出对应的特征向量，并标准化，得到最后的特征矩阵<span class="arithmatex"><span class="MathJax_Preview">F</span><script type="math/tex">F</script></span>，最后对<span class="arithmatex"><span class="MathJax_Preview">F</span><script type="math/tex">F</script></span>进行一次传统的聚类即可。</p>
<h2 id="_7">谱聚类总结<a class="headerlink" href="#_7" title="Permanent link">&para;</a></h2>
<p>谱聚类算法的主要优点有：</p>
<p>（1）谱聚类只需要数据之间的相似度矩阵，因此对于处理稀疏数据的聚类很有效。</p>
<p>（2）由于使用了降维，因此在处理高维数据聚类时的复杂度比传统聚类算法好。</p>
<p>谱聚类算法的主要缺点有：</p>
<p>（1）如果最终聚类的维度非常高，则由于降维的幅度不够，谱聚类的运行速度和最后的聚类效果均不好。</p>
<p>（2）聚类效果依赖于相似矩阵，不同的相似矩阵得到的最终聚类效果可能很不同。</p>

              
            </article>
          </div>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
    <nav class="md-footer__inner md-grid" aria-label="页脚">
      
        
        <a href="../28_%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95%E4%B9%8BMean%20Shift/" class="md-footer__link md-footer__link--prev" aria-label="上一页: 聚类算法之Mean Shift" rel="prev">
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
          </div>
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                上一页
              </span>
              聚类算法之Mean Shift
            </div>
          </div>
        </a>
      
      
        
        <a href="../30_%E9%99%8D%E7%BB%B4%E7%AE%97%E6%B3%95%E4%B9%8BPCA/" class="md-footer__link md-footer__link--next" aria-label="下一页: 降维算法之PCA" rel="next">
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                下一页
              </span>
              降维算法之PCA
            </div>
          </div>
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4Z"/></svg>
          </div>
        </a>
      
    </nav>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    <script id="__config" type="application/json">{"base": "../../..", "features": ["navigation.tabs"], "search": "../../../assets/javascripts/workers/search.2a1c317c.min.js", "translations": {"clipboard.copied": "\u5df2\u590d\u5236", "clipboard.copy": "\u590d\u5236", "search.config.lang": "ja", "search.config.pipeline": "trimmer, stemmer", "search.config.separator": "[\\uff0c\\u3002]+", "search.placeholder": "\u641c\u7d22", "search.result.more.one": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.other": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 # \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.term.missing": "\u7f3a\u5c11", "select.version.title": "\u9009\u62e9\u5f53\u524d\u7248\u672c"}}</script>
    
    
      <script src="../../../assets/javascripts/bundle.6e54b5cd.min.js"></script>
      
        <script src="../../../javascript/config.js"></script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML"></script>
      
    
  </body>
</html>