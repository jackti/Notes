
<!doctype html>
<html lang="zh" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="采用Mkdocs-material生成的文档管理网站支持的markdown语法，包括传统语法和扩展语法">
      
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.3.0, mkdocs-material-8.2.9">
    
    
      
        <title>CNN卷积神经网络 - 我的知识笔记</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.120efc48.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.9647289d.min.css">
        
          
          
          <meta name="theme-color" content="#2094f3">
        
      
    
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../..",location),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="" data-md-color-primary="blue" data-md-color-accent="pink">
  
    
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#cnn" class="md-skip">
          跳转至
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="页眉">
    <a href="../.." title="我的知识笔记" class="md-header__button md-logo" aria-label="我的知识笔记" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            我的知识笔记
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              CNN卷积神经网络
            
          </span>
        </div>
      </div>
    </div>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="搜索" placeholder="搜索" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="查找">
        
        <button type="reset" class="md-search__icon md-icon" aria-label="清空当前内容" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            正在初始化搜索引擎
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="标签" data-md-component="tabs">
  <div class="md-tabs__inner md-grid">
    <ul class="md-tabs__list">
      
        
  
  


  <li class="md-tabs__item">
    <a href="../.." class="md-tabs__link">
      首页
    </a>
  </li>

      
        
  
  


  
  
  
    

  
  
  
    <li class="md-tabs__item">
      <a href="../../%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/01_%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/00_%E5%85%B6%E4%BB%96%E8%AE%B0%E5%BD%95/" class="md-tabs__link">
        机器学习
      </a>
    </li>
  

  

      
        
  
  
    
  


  
  
  
    <li class="md-tabs__item">
      <a href="../00_%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/" class="md-tabs__link md-tabs__link--active">
        深度学习
      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="导航栏" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="我的知识笔记" class="md-nav__button md-logo" aria-label="我的知识笔记" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    我的知识笔记
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        首页
      </a>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_2" type="checkbox" id="__nav_2" >
      
      
      
      
        <label class="md-nav__link" for="__nav_2">
          机器学习
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="机器学习" data-md-level="1">
        <label class="md-nav__title" for="__nav_2">
          <span class="md-nav__icon md-icon"></span>
          机器学习
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_2_1" type="checkbox" id="__nav_2_1" >
      
      
      
      
        <label class="md-nav__link" for="__nav_2_1">
          01 监督学习
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="01 监督学习" data-md-level="2">
        <label class="md-nav__title" for="__nav_2_1">
          <span class="md-nav__icon md-icon"></span>
          01 监督学习
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/01_%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/00_%E5%85%B6%E4%BB%96%E8%AE%B0%E5%BD%95/" class="md-nav__link">
        数学符号
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/01_%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/00_%E6%80%BB%E7%BB%93/" class="md-nav__link">
        线性模型
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/01_%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/01_%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95/" class="md-nav__link">
        最小二乘法
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/01_%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/02_%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E7%AE%97%E6%B3%95/" class="md-nav__link">
        梯度下降算法
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/01_%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/03_%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81%E5%8E%9F%E7%90%86/" class="md-nav__link">
        交叉验证原理
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/01_%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/04_%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/" class="md-nav__link">
        模型评估
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/01_%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/05_%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86/" class="md-nav__link">
        线性回归算法原理
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/01_%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/06_%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86/" class="md-nav__link">
        逻辑回归算法原理
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/01_%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/07_%E5%86%B3%E7%AD%96%E6%A0%91%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86%28%E4%B8%80%29/" class="md-nav__link">
        决策树算法原理(一)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/01_%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/08_%E5%86%B3%E7%AD%96%E6%A0%91%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86%28%E4%BA%8C%29/" class="md-nav__link">
        决策树算法原理(二)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/01_%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/09_%E5%86%B3%E7%AD%96%E6%A0%91%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86%28%E4%B8%89%29/" class="md-nav__link">
        决策树算法原理(三)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/01_%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/10_%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86/" class="md-nav__link">
        近邻算法原理
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/01_%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/11_%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86/" class="md-nav__link">
        朴素贝叶斯算法原理
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/01_%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/12_%E6%9C%80%E5%A4%A7%E7%86%B5%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86%28%E4%B8%80%29/" class="md-nav__link">
        最大熵算法原理(一)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/01_%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/13_%E6%9C%80%E5%A4%A7%E7%86%B5%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86%28%E4%BA%8C%29/" class="md-nav__link">
        最大熵算法原理(二)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/01_%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/14_%E6%9C%80%E5%A4%A7%E7%86%B5%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86%28%E4%B8%89%29/" class="md-nav__link">
        最大熵算法原理(三)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/01_%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/15_%E6%84%9F%E7%9F%A5%E6%9C%BA%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86/" class="md-nav__link">
        感知机算法原理
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/01_%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/16_%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86%28%E4%B8%80%29/" class="md-nav__link">
        支持向量机算法原理(一)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/01_%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/17_%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86%28%E4%BA%8C%29/" class="md-nav__link">
        支持向量机算法原理(二)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/01_%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/18_%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86%28%E4%B8%89%29/" class="md-nav__link">
        支持向量机算法原理(三)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/01_%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/19_%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86%28%E5%9B%9B%29/" class="md-nav__link">
        支持向量机算法原理(四)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/01_%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/20_%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86%28%E4%BA%94%29/" class="md-nav__link">
        支持向量机算法原理(五)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/01_%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/21_%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E4%B9%8B%E7%BB%BC%E8%BF%B0/" class="md-nav__link">
        集成学习算法之综述
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/01_%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/22_%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E4%B9%8BAdaboost/" class="md-nav__link">
        集成学习算法之Adaboost
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/01_%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/23_%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E4%B9%8BRF/" class="md-nav__link">
        集成学习算法之RF
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/01_%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/24_%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E4%B9%8BGBDT/" class="md-nav__link">
        集成学习算法之GBDT
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_2_2" type="checkbox" id="__nav_2_2" >
      
      
      
      
        <label class="md-nav__link" for="__nav_2_2">
          02 无监督学习
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="02 无监督学习" data-md-level="2">
        <label class="md-nav__title" for="__nav_2_2">
          <span class="md-nav__icon md-icon"></span>
          02 无监督学习
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/02_%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/25_%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95%E4%B9%8BK-Means/" class="md-nav__link">
        聚类算法之K-Means​
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/02_%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/26_%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95%E4%B9%8BBIRCH/" class="md-nav__link">
        聚类算法之BIRCH
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/02_%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/27_%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95%E4%B9%8BDBSCAN/" class="md-nav__link">
        聚类算法之DBSCAN
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/02_%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/28_%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95%E4%B9%8BMean%20Shift/" class="md-nav__link">
        聚类算法之Mean Shift
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/02_%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/29_%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95%E4%B9%8B%E8%B0%B1%E8%81%9A%E7%B1%BB/" class="md-nav__link">
        聚类算法之谱聚类
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/02_%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/30_%E9%99%8D%E7%BB%B4%E7%AE%97%E6%B3%95%E4%B9%8BPCA/" class="md-nav__link">
        降维算法之PCA
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/02_%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/31_%E9%99%8D%E7%BB%B4%E7%AE%97%E6%B3%95%E4%B9%8BLDA/" class="md-nav__link">
        降维算法之LDA
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/02_%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/32_%E9%99%8D%E7%BB%B4%E7%AE%97%E6%B3%95%E4%B9%8BIsomap/" class="md-nav__link">
        降维算法之Isomap
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/02_%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/33_%E9%99%8D%E7%BB%B4%E7%AE%97%E6%B3%95%E4%B9%8BLLE/" class="md-nav__link">
        降维算法之LLE
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/02_%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/34_%E5%85%B3%E8%81%94%E7%AE%97%E6%B3%95%E4%B9%8BApriori/" class="md-nav__link">
        关联算法之Apriori
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/02_%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/35_%E5%85%B3%E8%81%94%E7%AE%97%E6%B3%95%E4%B9%8BFP-Tree/" class="md-nav__link">
        关联算法之FP-Tree
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/02_%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/36_%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95%E4%B9%8B%E7%BB%BC%E8%BF%B0/" class="md-nav__link">
        推荐算法之综述
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/02_%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/37_%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95%E4%B9%8B%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3/" class="md-nav__link">
        推荐算法之矩阵分解
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/02_%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/38_%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95%E4%B9%8BSimRank/" class="md-nav__link">
        推荐算法之SimRank
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/02_%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/39_%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95%E4%B9%8BPersonalRank/" class="md-nav__link">
        推荐算法之PersonalRank
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/02_%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/40_EM%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86/" class="md-nav__link">
        EM算法原理
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/02_%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/41_%E5%88%86%E8%A7%A3%E6%9C%BA%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86/" class="md-nav__link">
        分解机算法原理
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3" type="checkbox" id="__nav_3" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_3">
          深度学习
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="深度学习" data-md-level="1">
        <label class="md-nav__title" for="__nav_3">
          <span class="md-nav__icon md-icon"></span>
          深度学习
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../00_%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/" class="md-nav__link">
        神经网络基础
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../01_DNN%E5%89%8D%E9%A6%88%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" class="md-nav__link">
        DNN前馈神经网络
      </a>
    </li>
  

            
          
            
              
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          CNN卷积神经网络
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        CNN卷积神经网络
      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#cnn_1" class="md-nav__link">
    CNN前向传播算法
  </a>
  
    <nav class="md-nav" aria-label="CNN前向传播算法">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1" class="md-nav__link">
    （1）卷积层的前向传播计算
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2" class="md-nav__link">
    （2）池化层的前向传播计算
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_1" class="md-nav__link">
    误差反向传播算法
  </a>
  
    <nav class="md-nav" aria-label="误差反向传播算法">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1deltaldeltall-1l-1deltal-1deltal-1" class="md-nav__link">
    (1)已知池化层误差\delta^l\delta^l,求l-1l-1层误差\delta^{l-1}\delta^{l-1}
  </a>
  
    <nav class="md-nav" aria-label="(1)已知池化层误差\delta^l\delta^l,求l-1l-1层误差\delta^{l-1}\delta^{l-1}">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1_1" class="md-nav__link">
    ① 平均值池化后的上采样过程
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2_1" class="md-nav__link">
    ② 最大值池化后的上采样过程
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2deltaldeltall-1l-1deltal-1deltal-1" class="md-nav__link">
    (2)已知卷积层误差\delta^l\delta^l,求l-1l-1层误差\delta^{l-1}\delta^{l-1}
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../03_RNN%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" class="md-nav__link">
        RNN循环神经网络
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../04_%E5%9F%BA%E4%BA%8E%E9%97%A8%E6%8E%A7%E7%9A%84%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" class="md-nav__link">
        基于门控的循环神经网络
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../05_%E7%BD%91%E7%BB%9C%E4%BC%98%E5%8C%96%281%29/" class="md-nav__link">
        神经网络优化概述
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../05_%E7%BD%91%E7%BB%9C%E4%BC%98%E5%8C%96%282%29/" class="md-nav__link">
        数据预处理
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../06_%E7%BD%91%E7%BB%9C%E6%AD%A3%E5%88%99%E5%8C%96/" class="md-nav__link">
        网络正则化
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../07_%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/" class="md-nav__link">
        07 注意力机制
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#cnn_1" class="md-nav__link">
    CNN前向传播算法
  </a>
  
    <nav class="md-nav" aria-label="CNN前向传播算法">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1" class="md-nav__link">
    （1）卷积层的前向传播计算
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2" class="md-nav__link">
    （2）池化层的前向传播计算
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_1" class="md-nav__link">
    误差反向传播算法
  </a>
  
    <nav class="md-nav" aria-label="误差反向传播算法">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1deltaldeltall-1l-1deltal-1deltal-1" class="md-nav__link">
    (1)已知池化层误差\delta^l\delta^l,求l-1l-1层误差\delta^{l-1}\delta^{l-1}
  </a>
  
    <nav class="md-nav" aria-label="(1)已知池化层误差\delta^l\delta^l,求l-1l-1层误差\delta^{l-1}\delta^{l-1}">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1_1" class="md-nav__link">
    ① 平均值池化后的上采样过程
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2_1" class="md-nav__link">
    ② 最大值池化后的上采样过程
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2deltaldeltall-1l-1deltal-1deltal-1" class="md-nav__link">
    (2)已知卷积层误差\delta^l\delta^l,求l-1l-1层误差\delta^{l-1}\delta^{l-1}
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content" data-md-component="content">
            <article class="md-content__inner md-typeset">
              
                


<h1 id="cnn">CNN卷积神经网络<a class="headerlink" href="#cnn" title="Permanent link">&para;</a></h1>
<p>卷积神经网络(Convolutional Neural Network, CNN或ConvNet)是一种具有局部连接、权重共享等特性的深层前馈神经网络。卷积神经网络最早主要用来处理图像信息，在用全连接前馈网络来处理图像的时候，会存在以下两个问题：
（1）参数太多：全连接前馈网络随着隐藏层神经元数量的增多，参数的规模也会急剧增加．这会导致整个神经网络的训练效率非常低，也很容易出现过拟合．
（2）局部不变形特征：自然图像中的物体都具有局部不变性特征，比如尺度缩放、平移、旋转等操作不影响其语义信息．而全连接前馈网络很难提取这些局部不变性特征，一般需要进行数据增强来提高性能．卷积神经网络主要使用在图像和视频分析的各种任务（比如图像分类、人脸识别、物体识别、图像分割等）上，其准确率一般也远远超出了其他的神经网络模型.
卷积神经网络是受生物学上感受野机制的启发而提出来的。一个神经元的感受野是指视网膜上的特定区域，只有这个区域内的刺激才能够激活神经元。目前的卷积神经网络一般是卷积层、池化层和全连接层交叉堆叠而成的前馈神经网络。卷积层+池化层的组合可以在隐藏层出现多次，在若干卷积层+池化层后面是全连接层，即DNN层。
<img src="assets/CNN.jpg" alt="CNN.jpg" /></p>
<h2 id="cnn_1">CNN前向传播算法<a class="headerlink" href="#cnn_1" title="Permanent link">&para;</a></h2>
<p>卷积神经网络对比全连接神经网络，其保留了图像像素的空间排列信息。卷积操作将一个全连接层稀疏连接和共享参数。如图展示了全连接层到卷积层的转换过程。</p>
<p><img src="assets/CNN5.png" alt="CNN5.png" style="zoom:40%;"/></p>
<p>在卷积神经网络的前向传播过程中，不同类型的网络层其前向传播方式不同。下面分别说明卷积层、池化层的前向传播过程。</p>
<h3 id="1">（1）卷积层的前向传播计算<a class="headerlink" href="#1" title="Permanent link">&para;</a></h3>
<p>卷积层的前向传播公式为
$$
\boldsymbol{a}<em>{ij}^l 
= \sigma(\boldsymbol{z}^l</em>{ij})
=\sigma(\sum_{a}\sum_{b} \boldsymbol{W}<em>{a,b}^l \boldsymbol{a}</em>{i+a,j+b}<sup>{l-1}+\boldsymbol{b}</sup>l)  <br />
$$
其中<span class="arithmatex"><span class="MathJax_Preview">\boldsymbol{W}_{ab}^l</span><script type="math/tex">\boldsymbol{W}_{ab}^l</script></span>为卷积核的权重参数，<span class="arithmatex"><span class="MathJax_Preview">\boldsymbol{b}^l</span><script type="math/tex">\boldsymbol{b}^l</script></span>为偏置参数，<span class="arithmatex"><span class="MathJax_Preview">\sigma(\cdot)</span><script type="math/tex">\sigma(\cdot)</script></span>为卷积层节点的激活函数，<span class="arithmatex"><span class="MathJax_Preview">\boldsymbol{z}^l_{ij}</span><script type="math/tex">\boldsymbol{z}^l_{ij}</script></span>为卷积层节点的输入值，<span class="arithmatex"><span class="MathJax_Preview">\boldsymbol{a}^l_{ij}</span><script type="math/tex">\boldsymbol{a}^l_{ij}</script></span>为卷积层接点的激活值。卷积层前向传播计算的矩阵表达形式为：
$$
\boldsymbol{a}^l = \sigma(\boldsymbol{z}^l)
=\sigma(\boldsymbol{W}^l \ast \boldsymbol{a}<sup>{l-1}+\boldsymbol{b}</sup>l)
$$
其中<span class="arithmatex"><span class="MathJax_Preview">\ast</span><script type="math/tex">\ast</script></span>表示卷积运算。</p>
<blockquote>
<p>在卷积神经网络中的卷积运算，并不是数学上"卷积"运算，而是"互相关"运算。由于卷积核的参数是通过模型数据训练得到，所以在卷积神经网络中这两者并没有明显的差异。后面涉及到的卷积都是按照以上公式定义的。</p>
</blockquote>
<p>举例说明卷积的计算过程，图中输入是一个二维的<code>3×4</code>的矩阵，卷积核是一个<code>2×2</code>的矩阵，这里假设卷积是一次移动一个像素。在输出矩阵中第<code>00</code>位置的元素计算值为<code>aw+bx+ey+fz</code>。最终得到一个<code>2×3</code>的矩阵。这里有一个<a href="https://cs231n.github.io/assets/conv-demo/index.html">动态图的链接</a>说明卷积的计算过程。
<img src="assets/CNN2.png" alt="CNN2.png" style="zoom:80%;"/></p>
<p><a href="https://zhuanlan.zhihu.com/p/29119239">CNN卷积层的计算细节</a></p>
<h3 id="2">（2）池化层的前向传播计算<a class="headerlink" href="#2" title="Permanent link">&para;</a></h3>
<p>池化层是卷积神经网络中常用的组件之一，它最早见于<code>LeNet</code>网络中，被称之为<code>Subsample</code>.自从<code>AlexNet</code>之后采用<code>Pooling</code>命名。池化层是模仿人的视觉系统对数据进行降维，用更加高层次的特征表示图像。
池化层的作用：
1.  降低信息冗余；
2.  提升模型的尺度和旋转不变性；
3.  防止过拟合</p>
<p>最常见的两种池化操作为==最大值池化==和==平均值池化==等。
最大值池化的前向传播计算公式为
$$
\boldsymbol{a}<em>{ij}^l 
= \sigma(\boldsymbol{z}^l</em>{ij})
=\operatorname{max}({\boldsymbol{a}<em>{i+a,j+b}^{l-1}|a,b })
$$
平均值池化的前向传播计算公式为
$$
\boldsymbol{a}</em>{ij}^l 
= \sigma(\boldsymbol{z}^l_{ij})
=\frac{1}{k \times k}\sum_{a}<sup>{k1}\sum_{b}</sup>{k2}\boldsymbol{a}_{i+a,j+b}
$$
其中<span class="arithmatex"><span class="MathJax_Preview">k</span><script type="math/tex">k</script></span>为池化区域的大小。从上面的公式可以看到池化层是没有激活函数的，也没有权重参数和偏置采纳数。下图中给出最大值池化层的例子
<img src="assets/pooling.png" alt="pooling.jpg" style="zoom:80%;"/></p>
<h2 id="_1">误差反向传播算法<a class="headerlink" href="#_1" title="Permanent link">&para;</a></h2>
<p>在卷积神经网络的误差反向传播过程中，不同类型的网络层结构其反向传播方式也有所不同，首先回顾下DNN神经网络的反向传播公式.
关于第<span class="arithmatex"><span class="MathJax_Preview">i</span><script type="math/tex">i</script></span>层的第<span class="arithmatex"><span class="MathJax_Preview">j</span><script type="math/tex">j</script></span>个神经元错误量<span class="arithmatex"><span class="MathJax_Preview">\delta_j^l</span><script type="math/tex">\delta_j^l</script></span>定义为
$$
\delta_j^l =\frac{\partial C}{\partial \boldsymbol{z}^l_j} 
$$
最后一层关于错误量<span class="arithmatex"><span class="MathJax_Preview">\delta^L</span><script type="math/tex">\delta^L</script></span>的公式为
$$
\begin{aligned}
    \delta^L_j 
    &amp;= \frac{\partial C}{\partial \boldsymbol{z}^L_j}\
    &amp;=\frac{\partial C}{\partial \boldsymbol{a}^L_j} \frac{\partial \boldsymbol{a}^L_j }{\partial \boldsymbol{z}^L_j}\
    &amp;=\frac{\partial C}{\partial \boldsymbol{a}^L_j} \sigma^\prime (\boldsymbol{z}^L_j)
    \tag{BP-1}
\end{aligned}
$$</p>
<p>已知第<span class="arithmatex"><span class="MathJax_Preview">l+1</span><script type="math/tex">l+1</script></span>层的<span class="arithmatex"><span class="MathJax_Preview">\delta^{l+1}_j</span><script type="math/tex">\delta^{l+1}_j</script></span>，求第<span class="arithmatex"><span class="MathJax_Preview">l</span><script type="math/tex">l</script></span>层的错误量<span class="arithmatex"><span class="MathJax_Preview">\delta^{l+1}_j</span><script type="math/tex">\delta^{l+1}_j</script></span>公式
$$
\begin{aligned}
    \delta^l_j 
        &amp;=\frac{\partial C}{\partial \boldsymbol{z}<em>j^l}\
        &amp;=\sum_k \frac{\partial C}{\partial \boldsymbol{z}_k^{l+1}} \frac{\partial \boldsymbol{z}_k^{l+1}}{\partial \boldsymbol{a}^l_j} \frac{\boldsymbol{a}<sup>l_j}{\boldsymbol{z}</sup>l_j}\
        &amp;=\sum_k \delta_k^{l+1} \boldsymbol{W}</em>{kj}^{l+1} \sigma^\prime (\boldsymbol{z}_j^l)  \tag{BP-2}
\end{aligned}
$$</p>
<p>前馈神经网络中代价函数对于权重的改变速率公式
$$
\begin{aligned}
    \frac{\partial C}{\partial \boldsymbol{W}<em>{jk}^{l}}
        &amp;=\frac{\partial C}{\partial \boldsymbol{z}_k^{l}} \frac{\partial \boldsymbol{z}_k^{l}}{\partial \boldsymbol{W}</em>{jk}^{l}}\
        &amp;=\delta^l_j \boldsymbol{a}^{l-1}<em>k \tag{BP-3}
\end{aligned}
$$
前馈神经网络中代价函数对于偏置的改变速率公式
$$
\begin{aligned}
    \frac{\partial C}{\partial \boldsymbol{b}</em>{j}^{l}}
        &amp;=\frac{\partial C}{\partial \boldsymbol{z}<em>j^{l}} \frac{\partial \boldsymbol{z}_j^{l}}{\partial \boldsymbol{b}</em>{j}^{l}}\
        &amp;=\delta^l_j \cdot 1 \
        &amp;=\delta^l_j \tag{BP-4}
\end{aligned}
$$</p>
<h3 id="1deltaldeltall-1l-1deltal-1deltal-1">(1)已知池化层误差<span class="arithmatex"><span class="MathJax_Preview">\delta^l</span><script type="math/tex">\delta^l</script></span>,求<span class="arithmatex"><span class="MathJax_Preview">l-1</span><script type="math/tex">l-1</script></span>层误差<span class="arithmatex"><span class="MathJax_Preview">\delta^{l-1}</span><script type="math/tex">\delta^{l-1}</script></span><a class="headerlink" href="#1deltaldeltall-1l-1deltal-1deltal-1" title="Permanent link">&para;</a></h3>
<p>根据前面的相关推导，易知
$$
\begin{aligned}
    \delta^{l-1}<em>{ij} 
        &amp;=\frac{\partial C}{\partial \boldsymbol{z}</em>{ij}^{l-1}}\
        &amp;=\sum_{m}\sum_{n} \frac{\partial C}{\partial \boldsymbol{z}<em>{mm}^{l}} 
        \frac{\partial \boldsymbol{z}</em>{mm}^{l}}{\partial \boldsymbol{a}<em>{ij}^{l-1}} 
        \frac{\partial \boldsymbol{a}</em>{ij}^{l-1}}{\partial \boldsymbol{z}<em>{ij}^{l-1}} \
        &amp;=\sum</em>{m}\sum_{n} \delta_{mn}^l \frac{\partial \boldsymbol{z}<em>{mm}^{l}}{\partial \boldsymbol{a}</em>{ij}^{l-1}}  \sigma<sup>\prime(\boldsymbol{z}_{ij}</sup>{l-1})
\end{aligned}
$$
其中<span class="arithmatex"><span class="MathJax_Preview">\frac{\partial C}{\partial \boldsymbol{z}_{mn}^{l}}=\delta_{mn}^l</span><script type="math/tex">\frac{\partial C}{\partial \boldsymbol{z}_{mn}^{l}}=\delta_{mn}^l</script></span>，<span class="arithmatex"><span class="MathJax_Preview">\frac{\partial \boldsymbol{a}_{ij}^{l-1}}{\partial \boldsymbol{z}_{ij}^{l-1}}=\sigma^\prime(\boldsymbol{z}_{ij}^{l-1})</span><script type="math/tex">\frac{\partial \boldsymbol{a}_{ij}^{l-1}}{\partial \boldsymbol{z}_{ij}^{l-1}}=\sigma^\prime(\boldsymbol{z}_{ij}^{l-1})</script></span>,现在只剩下求<span class="arithmatex"><span class="MathJax_Preview">\frac{\partial \boldsymbol{z}_{mn}^{l}}{\partial \boldsymbol{a}_{ij}^{l-1}}</span><script type="math/tex">\frac{\partial \boldsymbol{z}_{mn}^{l}}{\partial \boldsymbol{a}_{ij}^{l-1}}</script></span>。</p>
<p>假设现在池化大小为<code>2×2</code>的区域，若使用平均值池化有
$$
\boldsymbol{z}<em>{mn}<sup>l=\frac{1}{4}(\boldsymbol{a}_{2m,2n}</sup>{l-1}+\boldsymbol{a}</em>{2m,2n+1}<sup>{l-1}+\boldsymbol{a}_{2m+1,2n}</sup>{l-1}+\boldsymbol{a}<em>{2m+1,2n+1}^{l-1})
$$
若使用最大值池化有
$$
\boldsymbol{z}</em>{mn}<sup>l=\operatorname{max}(\boldsymbol{a}_{2m,2n}</sup>{l-1}+\boldsymbol{a}<em>{2m,2n+1}<sup>{l-1}+\boldsymbol{a}_{2m+1,2n}</sup>{l-1}+\boldsymbol{a}</em>{2m+1,2n+1}^{l-1})
$$</p>
<p>可以看出，对于平均值池化有
$$
\frac{\partial \boldsymbol{z}<sup>l_{mn}}{\partial\boldsymbol{a}_{ij}</sup>{l-1}}=\frac{1}{k \times k}
$$
对于最大值池化有
$$
\frac{\partial \boldsymbol{z}<sup>l_{mn}}{\partial\boldsymbol{a}_{ij}</sup>{l-1}}=
\left{
\begin{aligned}
1 \qquad  \boldsymbol{a}<em>{mn}^{l-1} =\operatorname{max}\
0 \qquad  \boldsymbol{a}</em>{mn}^{l-1} \ne \operatorname{max} 
\end{aligned}
\right.
$$</p>
<p>根据上面的公式，可以对池化层的误差矩阵<span class="arithmatex"><span class="MathJax_Preview">\delta^l</span><script type="math/tex">\delta^l</script></span>进行<code>上采样</code>操作.
假设现有池化大小为<code>2×2</code>的区域，误差矩阵如下
$$
\delta^l =
 \left[
 \begin{matrix}
   2 &amp; 4 \
   6 &amp; 8 \
  \end{matrix}
  \right]
$$</p>
<h4 id="1_1">① 平均值池化后的上采样过程<a class="headerlink" href="#1_1" title="Permanent link">&para;</a></h4>
<p>若是平均值池化，那么上采样后每个区域的值为池化层对应的值在乘以<span class="arithmatex"><span class="MathJax_Preview">\frac{1}{k\times k}</span><script type="math/tex">\frac{1}{k\times k}</script></span>，得到
$$
\operatorname{upsample}(\delta^l) =
 \left[
 \begin{matrix}
   0.5 &amp; 0.5 &amp; 1 &amp; 1\
   0.5 &amp; 0.5 &amp; 1 &amp; 1\
   1.5 &amp; 1.5 &amp; 2 &amp; 2\
   1.5 &amp; 1.5 &amp; 2 &amp; 2\
  \end{matrix}
  \right]
$$
这个过程可以用以下公式表示
$$
\operatorname{upsample}(\delta^l) = \delta^l \otimes 1_{k \times k} \odot\frac{1}{k \times k}
$$
其中<span class="arithmatex"><span class="MathJax_Preview">\otimes</span><script type="math/tex">\otimes</script></span>表示克罗内克积，<span class="arithmatex"><span class="MathJax_Preview">\odot</span><script type="math/tex">\odot</script></span>表示按元素相乘。</p>
<h4 id="2_1">② 最大值池化后的上采样过程<a class="headerlink" href="#2_1" title="Permanent link">&para;</a></h4>
<p>若为最大值，上采样时先将误差矩阵<span class="arithmatex"><span class="MathJax_Preview">\delta^l</span><script type="math/tex">\delta^l</script></span>还原，再将每个区域的误差移动到前向传播时最大值所在的位置上。比如记录的位置分别为<code>(0,0),(1,3),(3,1),(2,2)</code>则上采样<span class="arithmatex"><span class="MathJax_Preview">\operatorname{upsample}(\delta^l)</span><script type="math/tex">\operatorname{upsample}(\delta^l)</script></span>的过程为
$$
\delta^l =
 \left[
 \begin{matrix}
   2 &amp; 4 \
   6 &amp; 8 \
  \end{matrix}
  \right]
\Longrightarrow
 \left[
 \begin{matrix}
   0 &amp; 0 &amp; 0 &amp; 0\
   0 &amp; 2 &amp; 4 &amp; 0\
   0 &amp; 6 &amp; 8 &amp; 0\
   0 &amp; 0 &amp; 0 &amp; 0\
  \end{matrix}
  \right]
\Longrightarrow
   \left[
 \begin{matrix}
   2 &amp; 0 &amp; 0 &amp; 0\
   0 &amp; 0 &amp; 0 &amp; 4\
   0 &amp; 0 &amp; 8 &amp; 0\
   0 &amp; 6 &amp; 0 &amp; 0\
  \end{matrix}
  \right]
$$</p>
<p>最后，在已知池化层误差<span class="arithmatex"><span class="MathJax_Preview">\delta^l</span><script type="math/tex">\delta^l</script></span>,求<span class="arithmatex"><span class="MathJax_Preview">l-1</span><script type="math/tex">l-1</script></span>层误差<span class="arithmatex"><span class="MathJax_Preview">\delta^{l-1}</span><script type="math/tex">\delta^{l-1}</script></span>为
$$
\begin{aligned}
        \delta^{l-1} 
        &amp;=\frac{\partial C}{\partial \boldsymbol{z}^{l-1}}\
        &amp;=\frac{\partial C}{\partial \boldsymbol{z}^{l}} \frac{\partial \boldsymbol{z}^{l}}{\partial \boldsymbol{a}^{l-1}} \frac{\partial \boldsymbol{a}^{l-1}}{\partial \boldsymbol{z}^{l-1}}\
        &amp;=\operatorname{upsample}(\delta^l) \odot \sigma<sup>\prime(\boldsymbol{z}</sup>{l-1})
        \tag{CNN-1}
\end{aligned}
$$</p>
<h3 id="2deltaldeltall-1l-1deltal-1deltal-1">(2)已知卷积层误差<span class="arithmatex"><span class="MathJax_Preview">\delta^l</span><script type="math/tex">\delta^l</script></span>,求<span class="arithmatex"><span class="MathJax_Preview">l-1</span><script type="math/tex">l-1</script></span>层误差<span class="arithmatex"><span class="MathJax_Preview">\delta^{l-1}</span><script type="math/tex">\delta^{l-1}</script></span><a class="headerlink" href="#2deltaldeltall-1l-1deltal-1deltal-1" title="Permanent link">&para;</a></h3>
<p>根据前面的公式<code>BP-2</code>有
$$
\delta^{l-1}<em>j 
=\sum_k \delta_k^{l} \boldsymbol{W}</em>{kj}^{l} \sigma^\prime (\boldsymbol{z}_j^{l-1}) 
$$
第<span class="arithmatex"><span class="MathJax_Preview">l-1</span><script type="math/tex">l-1</script></span>层中的第<span class="arithmatex"><span class="MathJax_Preview">j</span><script type="math/tex">j</script></span>个结点误差<span class="arithmatex"><span class="MathJax_Preview">\delta^{l-1}_j</span><script type="math/tex">\delta^{l-1}_j</script></span>与前面的第<span class="arithmatex"><span class="MathJax_Preview">l</span><script type="math/tex">l</script></span>层中与其相连的神经元<span class="arithmatex"><span class="MathJax_Preview">k</span><script type="math/tex">k</script></span>的误差<span class="arithmatex"><span class="MathJax_Preview">\delta^l_k</span><script type="math/tex">\delta^l_k</script></span>以及两者之间的权重有关。由于卷积操作是局部感知和权重共享，因此误差传播过程和DNN是有所差异的。
首先给出一个具体的示例说明计算推导的过程以便于理解，之后再给出详尽的证明。现假设输入的矩阵大小为<code>3×3</code>,卷积核的大小为<code>2×2</code>，输出的矩阵大小为<code>2×2</code></p>
<p><img src="assets/CNN3.png" alt="CNN3.png"/></p>
<p>将上面的卷积过程展开，并用神经网络的形式描述——权重上的标注是其在卷积核中的位置,相同的权重用同一种颜色表示.</p>
<p><img src="assets/CNN4.png" alt="CNN4.png"/>
根据上图的连接情况可以如下的计算过程</p>
<p>$$
\begin{aligned}
    \delta<sup>{l-1}_{00}&amp;=(\delta</sup>{l}<em>{00}\boldsymbol{W}<sup>{l}_{00})\sigma</sup>{\prime}(\boldsymbol{z}^{l-1}</em>{00})\
    \delta<sup>{l-1}_{01}&amp;=(\delta</sup>{l}<em>{00}\boldsymbol{W}<sup>{l}_{01}+\delta</sup>{l}</em>{01}\boldsymbol{W}<sup>{l}_{00})\sigma</sup>{\prime}(\boldsymbol{z}^{l-1}<em>{01})\
    \delta<sup>{l-1}_{02}&amp;=(\delta</sup>{l}</em>{01}\boldsymbol{W}<sup>{l}_{01})\sigma</sup>{\prime}(\boldsymbol{z}^{l-1}<em>{02})\
    \delta<sup>{l-1}_{10}&amp;=(\delta</sup>{l}</em>{00}\boldsymbol{W}<sup>{l}_{10}+\delta</sup>{l}<em>{10}\boldsymbol{W}<sup>{l}_{00})\sigma</sup>{\prime}(\boldsymbol{z}^{l-1}</em>{10})\
    \delta<sup>{l-1}_{11}&amp;=(\delta</sup>{l}<em>{00}\boldsymbol{W}<sup>{l}_{11}+\delta</sup>{l}</em>{01}\boldsymbol{W}<sup>{l}_{10}+\delta</sup>{l}<em>{10}\boldsymbol{W}<sup>{l}_{01}+\delta</sup>{l}</em>{11}\boldsymbol{W}<sup>{l}_{00})\sigma</sup>{\prime}(\boldsymbol{z}^{l-1}<em>{11})\
    \delta<sup>{l-1}_{12}&amp;=(\delta</sup>{l}</em>{01}\boldsymbol{W}<sup>{l}_{11}+\delta</sup>{l}<em>{11}\boldsymbol{W}<sup>{l}_{01})\sigma</sup>{\prime}(\boldsymbol{z}^{l-1}</em>{12})\
    \delta<sup>{l-1}_{20}&amp;=(\delta</sup>{l}<em>{10}\boldsymbol{W}<sup>{l}_{10})\sigma</sup>{\prime}(\boldsymbol{z}^{l-1}</em>{20})\
    \delta<sup>{l-1}_{21}&amp;=(\delta</sup>{l}<em>{10}\boldsymbol{W}<sup>{l}_{11}+\delta</sup>{l}</em>{11}\boldsymbol{W}<sup>{l}_{10})\sigma</sup>{\prime}(\boldsymbol{z}^{l-1}<em>{21})\
    \delta<sup>{l-1}_{22}&amp;=(\delta</sup>{l}</em>{11}\boldsymbol{W}<sup>{l}_{11})\sigma</sup>{\prime}(\boldsymbol{z}^{l-1}<em>{22})
\end{aligned}
$$
可以将上面的9个式子用矩阵形式统一表示
$$
\left[
 \begin{matrix}
   0 &amp; 0 &amp; 0 &amp; 0\
   0 &amp; \delta</em>{00}^l &amp; \delta_{01}^l &amp; 0\
   0 &amp; \delta_{10}^l &amp; \delta_{11}^l &amp; 0\
   0 &amp; 0 &amp; 0 &amp; 0\
  \end{matrix} 
\right]
  \ast
  \left[
  \begin{matrix}
\boldsymbol{W}<em>{00}^l &amp;\boldsymbol{W}</em>{01}^l \
\boldsymbol{W}<em>{10}^l &amp; \boldsymbol{W}</em>{11}^l 
  \end{matrix} 
  \right]
  \odot
\left[
  \begin{matrix}
\sigma<sup>{\prime}(\boldsymbol{z_{00}</sup>{l}}) &amp;\sigma<sup>{\prime}(\boldsymbol{z_{01}</sup>{l}}) &amp;\sigma<sup>{\prime}(\boldsymbol{z_{02}</sup>{l}})   \
\sigma<sup>{\prime}(\boldsymbol{z_{10}</sup>{l}}) &amp;\sigma<sup>{\prime}(\boldsymbol{z_{11}</sup>{l}}) &amp;\sigma<sup>{\prime}(\boldsymbol{z_{12}</sup>{l}})   \
\sigma<sup>{\prime}(\boldsymbol{z_{20}</sup>{l}}) &amp;\sigma<sup>{\prime}(\boldsymbol{z_{21}</sup>{l}}) &amp;\sigma<sup>{\prime}(\boldsymbol{z_{22}</sup>{l}}) <br />
  \end{matrix} 
  \right] =
  \left[
    \begin{matrix}
\sigma_{00}^{l-1} &amp;\sigma_{01}^{l-1} &amp;\sigma_{02}^{l-1}   \ 
\sigma_{10}^{l-1} &amp;\sigma_{11}^{l-1} &amp;\sigma_{12}^{l-1}   \ 
\sigma_{20}^{l-1} &amp;\sigma_{21}^{l-1} &amp;\sigma_{22}^{l-1}   \ 
  \end{matrix} 
  \right]
$$
先在误差矩阵<span class="arithmatex"><span class="MathJax_Preview">\delta^l</span><script type="math/tex">\delta^l</script></span>周围填上一圈0，然后将卷积核<span class="arithmatex"><span class="MathJax_Preview">\boldsymbol{W}^l</span><script type="math/tex">\boldsymbol{W}^l</script></span>旋转180,两者进行卷积，再与矩阵<span class="arithmatex"><span class="MathJax_Preview">\delta^{\prime}(\boldsymbol{z}^{l-1})</span><script type="math/tex">\delta^{\prime}(\boldsymbol{z}^{l-1})</script></span>按元素相乘，就得到了前一层的误差矩阵<span class="arithmatex"><span class="MathJax_Preview">\delta^{l-1}</span><script type="math/tex">\delta^{l-1}</script></span>，用数学公式表示为
$$
\delta<sup>{l-1}=\delta</sup>l \ast \operatorname{rot180}(\boldsymbol{W}<sup>l)\odot\sigma</sup>{\prime}(\boldsymbol{z}^{l-1})
\tag{CNN-2}
$$
上面的推导是以一个简单的示例进行拼凑的"证明"，下面给出严格完整的数学形式.
$$
\begin{aligned}
\delta_{i, j}^{l-1} &amp;=\frac{\partial C}{\partial \boldsymbol{z}<em>{i, j}^{l-1}} \
&amp;=\sum</em>{m} \sum_{n} \frac{\partial C}{\partial \boldsymbol{z}<em>{m, n}^{l}} \frac{\partial \boldsymbol{z}</em>{m, n}^{l}}{\partial \boldsymbol{z}<em>{i, j}^{l-1}} \
&amp;=\sum</em>{m} \sum_{n} \delta_{m, n}^{l} \frac{\partial \boldsymbol{z}<em>{m, n}^{l}}{\partial \boldsymbol{a}</em>{i, j}^{l-1}} \frac{\partial \boldsymbol{a}<em>{i, j}^{l-1}}{\partial \boldsymbol{z}</em>{i, j}^{l-1}} \
&amp;=\sum_{m} \sum_{n} \delta_{m, n}^{l} \frac{\partial\left(\sum_{a} \sum_{b} \boldsymbol{W}<em>{a, b}^{l} \boldsymbol{a}</em>{m+a, n+b}<sup>{l-1}+b</sup>{l+1}\right)}{\partial \boldsymbol{a}<em>{i, j}^{l-1}} \sigma^{\prime}\left(\boldsymbol{z}</em>{i, j}^{l-1}\right) \
&amp;\xlongequal[m+a=i]{n+b=j} \sum_{m} \sum_{n} \delta_{m, n}^{l} \boldsymbol{W}<em>{i-m, j-n}^{l} \sigma^{\prime}\left(\boldsymbol{z}</em>{i, j}^{l-1}\right)
\end{aligned}
$$
将上面的式子写成矩阵的就是公式<code>CNN-2</code>了。</p>
<p>在已知当前层的结点误差，那么第<span class="arithmatex"><span class="MathJax_Preview">l</span><script type="math/tex">l</script></span>层的卷积核节点的权重梯度公式为
$$
\begin{aligned}
\frac{\partial C}{\partial \boldsymbol{W}<em>{i, j}^{l}} &amp;=\sum</em>{m} \sum_{n} \frac{\partial C}{\partial \boldsymbol{z}<em>{m, n}^{l}} \frac{\partial \boldsymbol{z}</em>{m, n}^{l}}{\partial \boldsymbol{W}<em>{i, j}^{l}} \
&amp;=\sum</em>{m} \sum_{n} \delta_{m, n}^{l} \frac{\partial\left(\sum_{a} \sum_{b} \boldsymbol{W}<em>{a, b}^{l} \boldsymbol{a}</em>{m+a, n+b}<sup>{l-1}+\boldsymbol{b}</sup>{l}\right)}{\partial \boldsymbol{W}<em>{i, j}^{l}} \
&amp; \xlongequal[a=i]{b=j} \sum</em>{m} \sum_{n} \delta_{m, n}^{l} \boldsymbol{a}_{m+i, n+j}^{l-1}
\tag{CNN-3}
\end{aligned}
$$
上面公式的矩阵形式为
$$
\frac{\partial C}{\partial \boldsymbol{W}^{l}} =
\delta^{l}\ast \boldsymbol{a}^{l-1}
\tag{CNN-3}
$$</p>
<p>同理，在已知当前层的结点误差，那么第<span class="arithmatex"><span class="MathJax_Preview">l</span><script type="math/tex">l</script></span>层的卷积核节点的偏置梯度公式为
$$
\begin{aligned}
\frac{\partial C}{\partial \boldsymbol{b}^{l}} &amp;=\sum_{m} \sum_{n} \frac{\partial C}{\partial \boldsymbol{z}<em>{m, n}^{l}} \frac{\partial \boldsymbol{z}</em>{m, n}^{l}}{\partial \boldsymbol{b}^{l}} \
&amp;=\sum_{m} \sum_{n} \delta_{m, n}^{l}
\end{aligned}
$$
因为每一个卷积核只有一个共享的偏置参数，所以上面公式中<span class="arithmatex"><span class="MathJax_Preview">\boldsymbol{b}^{l} \in \mathbb{R}</span><script type="math/tex">\boldsymbol{b}^{l} \in \mathbb{R}</script></span>,是一个实数。将上面公式的矩阵形式为
$$
\frac{\partial C}{\partial \boldsymbol{b}^{l}} = \delta^l \tag{CNN-4}
$$</p>
<p>综上，CNN反向传播过程中四个重要公式<code>CNN-1</code>,<code>CNN-2</code>,<code>CNN-3</code>,<code>CNN-4</code>总结如下</p>
<table>
<thead>
<tr>
<th align="center">公式</th>
<th align="left">元素形式</th>
<th align="center">矩阵形式</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center">CNN-1</td>
<td align="left"><span class="arithmatex"><span class="MathJax_Preview">\delta^{l-1}_{ij}=\sum_{m}\sum_{n} \delta_{mn}^l \frac{\partial \boldsymbol{z}_{mm}^{l}}{\partial \boldsymbol{a}_{ij}^{l-1}}  \sigma^\prime(\boldsymbol{z}_{ij}^{l-1})</span><script type="math/tex">\delta^{l-1}_{ij}=\sum_{m}\sum_{n} \delta_{mn}^l \frac{\partial \boldsymbol{z}_{mm}^{l}}{\partial \boldsymbol{a}_{ij}^{l-1}}  \sigma^\prime(\boldsymbol{z}_{ij}^{l-1})</script></span></td>
<td align="center"><span class="arithmatex"><span class="MathJax_Preview">\delta^{l-1}=\operatorname{upsample}(\delta^l) \odot \sigma^\prime(\boldsymbol{z}^{l-1})</span><script type="math/tex">\delta^{l-1}=\operatorname{upsample}(\delta^l) \odot \sigma^\prime(\boldsymbol{z}^{l-1})</script></span></td>
</tr>
<tr>
<td align="center">CNN-2</td>
<td align="left"><span class="arithmatex"><span class="MathJax_Preview">\delta_{i, j}^{l-1}= \sum_{m} \sum_{n} \delta_{m, n}^{l} \boldsymbol{W}_{i-m, j-n}^{l} \sigma^{\prime}\left(\boldsymbol{z}_{i, j}^{l-1}\right)</span><script type="math/tex">\delta_{i, j}^{l-1}= \sum_{m} \sum_{n} \delta_{m, n}^{l} \boldsymbol{W}_{i-m, j-n}^{l} \sigma^{\prime}\left(\boldsymbol{z}_{i, j}^{l-1}\right)</script></span></td>
<td align="center"><span class="arithmatex"><span class="MathJax_Preview">\delta^{l-1}=\delta^l \ast \operatorname{rot180}(\boldsymbol{W}^l)\odot\sigma^{\prime}(\boldsymbol{z}^{l-1})</span><script type="math/tex">\delta^{l-1}=\delta^l \ast \operatorname{rot180}(\boldsymbol{W}^l)\odot\sigma^{\prime}(\boldsymbol{z}^{l-1})</script></span></td>
</tr>
<tr>
<td align="center">CNN-3</td>
<td align="left"><span class="arithmatex"><span class="MathJax_Preview">\frac{\partial C}{\partial \boldsymbol{W}^l_{jk}}=\sum_{m} \sum_{n} \delta_{m, n}^{l} \boldsymbol{a}_{m+i, n+j}^{l-1}</span><script type="math/tex">\frac{\partial C}{\partial \boldsymbol{W}^l_{jk}}=\sum_{m} \sum_{n} \delta_{m, n}^{l} \boldsymbol{a}_{m+i, n+j}^{l-1}</script></span></td>
<td align="center"><span class="arithmatex"><span class="MathJax_Preview">\frac{\partial C}{\partial \boldsymbol{W}^{l}} =\delta^{l}\ast \boldsymbol{a}^{l-1}</span><script type="math/tex">\frac{\partial C}{\partial \boldsymbol{W}^{l}} =\delta^{l}\ast \boldsymbol{a}^{l-1}</script></span></td>
</tr>
<tr>
<td align="center">CNN-4</td>
<td align="left"><span class="arithmatex"><span class="MathJax_Preview">\frac{\partial C}{\partial \boldsymbol{b}^l_{j}}=\sum_{m} \sum_{n} \delta_{m, n}^{l}</span><script type="math/tex">\frac{\partial C}{\partial \boldsymbol{b}^l_{j}}=\sum_{m} \sum_{n} \delta_{m, n}^{l}</script></span></td>
<td align="center"><span class="arithmatex"><span class="MathJax_Preview">\frac{\partial C}{\partial \boldsymbol{b}^l}=\delta^l</span><script type="math/tex">\frac{\partial C}{\partial \boldsymbol{b}^l}=\delta^l</script></span></td>
</tr>
</tbody>
</table>

              
            </article>
          </div>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
    <nav class="md-footer__inner md-grid" aria-label="页脚">
      
        
        <a href="../01_DNN%E5%89%8D%E9%A6%88%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" class="md-footer__link md-footer__link--prev" aria-label="上一页: DNN前馈神经网络" rel="prev">
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
          </div>
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                上一页
              </span>
              DNN前馈神经网络
            </div>
          </div>
        </a>
      
      
        
        <a href="../03_RNN%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" class="md-footer__link md-footer__link--next" aria-label="下一页: RNN循环神经网络" rel="next">
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                下一页
              </span>
              RNN循环神经网络
            </div>
          </div>
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4Z"/></svg>
          </div>
        </a>
      
    </nav>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    <script id="__config" type="application/json">{"base": "../..", "features": ["navigation.tabs"], "search": "../../assets/javascripts/workers/search.2a1c317c.min.js", "translations": {"clipboard.copied": "\u5df2\u590d\u5236", "clipboard.copy": "\u590d\u5236", "search.config.lang": "ja", "search.config.pipeline": "trimmer, stemmer", "search.config.separator": "[\\uff0c\\u3002]+", "search.placeholder": "\u641c\u7d22", "search.result.more.one": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.other": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 # \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.term.missing": "\u7f3a\u5c11", "select.version.title": "\u9009\u62e9\u5f53\u524d\u7248\u672c"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.6e54b5cd.min.js"></script>
      
        <script src="../../javascript/config.js"></script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML"></script>
      
    
  </body>
</html>