# 朴素贝叶斯算法原理

监督学习的任务就是学习一个模型，应用这个模型，对给定的输入预测相应的输出。监督学习方法又可以分为生成方法和判别方法，所学到的模型分别称为生成模型和判别模型。

判别方法：由数据直接学习决策函数$Y=f(X)$或者条件概率分布$P(Y|X)$作为预测的模型，即判别模型。基本思想是有限样本条件下建立判别函数，不考虑样本的产生模型，直接研究预测模型。不能反映训练数据本身的特性，它寻找不同类别之间的最优分类面，反映的是异类数据之间的差异。典型的判别模型包括$k$近邻、感知机、决策树和支持向量机等。

生成方法：由数据学习联合概率密度分布$P(X,Y)$，然后求出条件概率分布$P(Y|X)$作为预测的模型，即生成模型：$P(Y|X)=\frac{P(X,Y)}{P(X)}$。基本思想是首先建立样本的联合概率密度模型$P(X,Y)$，然后再得到后验概率$P(Y|X)$，在利用它进行分类。从统计的角度表示数据的分布情况，能够反映同类数据本身的相似度。但它不关心到底划分各类的那个分类边界在哪。典型的生成模型包括朴素贝叶斯方法、隐马尔可夫模型。



## 朴素贝叶斯模型

假设数据样本是：

$$
(x_1^{(1)},x_2^{(1)},...,x_n^{(1)},y^{(1)}),(x_1^{(2)},x_2^{(2)},...,x_n^{(2)},y^{(2)}),...,(x_1^{(m)},x_2^{(m)},...,x_n^{(m)},y^{(m)})
$$

其中有$m$个样本，每个样本有$n$个特征，输出有$K$个类别即$y^{(i)}\in\{C_1,C_2,...,C_K \}$。

朴素贝叶斯通过训练数据集学习联合概率密度分布$P(X,Y)$，其定义为：

$$
\begin{align}
P(X,Y=C_k)&=P(Y=C_k)P(X=x|Y=C_k) \tag{1}\\
&=P(Y=C_k)P(X_1=x_1,X_2=x_2,...,X_n=x_n|Y=C_k) \tag{2}
\end{align}
$$

公式(1)利用了条件概率的定义，公式(2)对比公式(1)只是将$X=x$换成了$X_1=x_1,X_2=x_2,...,X_n=x_n$ 其中$X_1,X_2,...,X_n$表示$X$的每一特征维度。从上面的公式中，可以发现$P(Y=C_k)$就是类别$C_k$在训练集里面出现的频率。
然而$P(X_1=x_1,X_2=x_2,...,X_n=x_n|Y=C_k)$很难求出，这是一个很复杂的$n$维度条件分布。

----------

朴素贝叶斯模型在这里做了一个大胆的假设——$X$的$n$个维度之间互相独立，于是公式(1)可以简化为：

$$
\begin{align}
P(X,Y=C_k)&=P(Y=C_k)P(X=x|Y=C_k)\\
&=P(Y=C_k)P(X_1=x_1,X_2=x_2,...,X_n=x_n|Y=C_k)\\
&=P(Y=C_k)P(X_1=x_1|Y=C_k)P(X_2=x_2|Y=C_k)...P(X_n=x_n|Y=C_k)
\end{align}
$$

这个大胆的假设大大化简了上述条件分布，但是这也可能会带来预测的不准确性。朴素贝叶斯法实际上学习到生成数据的机制，所以属于生成模型。



## 朴素贝叶斯的推断过程

对于给定测试集的一个新样本特征$(x_1^{(test)},x_2^{(test)},...,x_n^{(test)})$，可以使用后验概率最大化来判断新样本所属的类别，只需要计算出所有$K$个条件概率$P(Y=C_k|X=X^{(test)}$，然后找到最大的后验概率所对应的类别，这就是朴素贝叶斯的预测。数学表达式如下：

$$
\begin{align}
& \arg \max_{C_k} P(Y=C_k|X=X^{(test)}) \label{3}\\
=& \arg  \max_{C_k} \frac{P(X=X^{(test)}|Y=C_k)P(Y=C_k)}{p(X=X^{(test)})} \tag{4}\\
\propto  &   \arg  \max_{C_k} P(X=X^{(test)}|Y=C_k)P(Y=C_k) \tag{5}\\
=&  \arg  \max_{C_k} P(Y=C_k)\prod_{j=1}^n P(X_j=X_j^{(test)}|Y=C_k) \tag{6}
\end{align}
$$

公式(4)~(5)利用条件概率的定义

公式(5)~(6) 由于对于所有类别计算时，公式(5)中的分母都是一样的，所以可以直接去掉分母

公式(6)~(7)利用前面提到的假设：$X$的$n$个维度之间互相独立。



## 朴素贝叶斯算法流程

假设输入数据样本是：

$$
(x_1^{(1)},x_2^{(1)},...,x_n^{(1)},y^{(1)}),(x_1^{(2)},x_2^{(2)},...,x_n^{(2)},y^{(2)}),...,(x_1^{(m)},x_2^{(m)},...,x_n^{(m)},y^{(m)})
$$

其中有$m$个样本，每个样本有$n$个特征，输出有$K$个类别即$y^{(i)}\in\{C_1,C_2,...,C_K \}$，每个类别的样本个数为$m_1,m_2,...,m_K$，在第$k$个类别中，如果是离散值，那么特征$X_j$各个取值的个数$m_{jl}$，其中$l$取值为$1,2,...,S_j$，$S_j$为特征$j$不同的取值数。

算法流程如下：

(1)如果没有$Y$的先验概率，则计算$Y$的$K$个先验概率：$P(Y=C_k)=\frac{m_k}{m}$，否则$P(Y=C_k)$为输入的先验概率。

(2)分别计算第$k$个类别的第$j$维度的第$i$个取值条件概率：$P(X_j=x_{jl}|Y=C_k)$

+ 如果是离散值

$$
  P(X_j=x_{jl}|Y=C_k)=\frac{x_{jl}+\lambda}{m_k+n\lambda}
$$

  $\lambda$取值通常取值为1。

+ 如果是稀疏二项离散值

$$
  P(X_j=x_{jl}|Y=C_k)=P(j|Y=C_k)x_{jl}+(1-P(j|Y=C_k))(1-x_{jl})
$$

  其中$l$只取两种值。

+ 如果是连续值不需要计算各个$l$的取值概率，直接求正态分布参数

$$
  P(X_j=x_j|Y=C_k)=\frac{1}{\sqrt{2\pi\sigma^2_k}}\exp(-\frac{(x_j-u_k)^2}{2\sigma^2_k})
$$

  其中$u_k$为在样本类别为$C_k$中，所有$X_j$的平均值。$\sigma^2_k$为在样本为$C_k$中，所有$X_j$的方差。

（3）对于预测实例$X^{(test)}$，分别计算：

$$
 P(Y=C_k)\prod_{j=1}^n P(X_j=X_j^{(test)}|Y=C_k)
$$

（4）确定预测实例$X^{(test)}$的分类$C_{result}$：

$$
C_{result}=\arg  \max_{C_k} P(Y=C_k)\prod_{j=1}^n P(X_j=X_j^{(test)}|Y=C_k)
$$










































