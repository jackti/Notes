# 交叉验证原理

在训练有监督的机器学习模型的时候，如果数据量足够充足，我们通常会将数据划分为训练集（Training Set）、验证集（Validation Set）和测试集（Test Set），划分比例一般设置为0.6:0.2:0.2。这样是为了能够选出效果最好的、泛化能力最强的算法模型。

## 训练集

用来拟合模型，通过选择不同的分类模型或者模型同一参数的不同取值，训练分类模型，得到多个不同的分类器。

## 验证集

当通过训练得到多个模型后，为了能找出效果最佳的模型，使用各个模型对验证集数据进行预测，并记录下模型预测指标。选出效果最佳的模型所对应的参数，即用来调整模型参数，比如神经网络模型中隐藏节点的个数，`SVM`模型中参数$C$ 和核函数等。

## 测试集

通过训练集和验证集得到最优模型后，使用测试集对模型预测，用来衡量该最优模型的性能和泛化能力。可以把测试集当做从来不存在的数据，当已经确定模型参数后，使用测试集进行模型性能评估。

然而很多时候，在我们的项目中，样本数据量很少，比如小于一万条的时候，我们就需要使用交叉验证来训练优化选择模型。

## 交叉验证

交叉验证是在机器学习建立模型和验证模型参数时常用的办法。交叉验证就是为了重复地使用数据，把得到的样本数据进行切分，组合为不同的训练集和测试集，用训练集来训练模型，用测试集来评估模型预测的好坏。在此基础上可以得到多组不同的训练集和测试集，某次训练集中的某样本在下次可能成为测试集中的样本，即所谓`交叉`。

根据切分的方法不同，交叉验证一般分为下面三种：

### 简单交叉验证

首先，我们随机的讲样本数据划分为两部分（比如70%的训练集，30% 的测试集），然后用训练集来训练模型，在测试集上验证模型及参数。接着，我们再把样本打乱，重新选择训练集和测试集，继续训练数据和检验模型 。最后我们选择损失函数评估最优的模型和参数。

### $S$折交叉验证

数据随机划分为$S$个互不相同且大小相同的子集，利用$S-1$个子集数据训练模型，利用余下的一个子集测试模型（一共有$C_S^{S-1}=S$中组合）。对$S$种组合依次进行重复进行，获取测试误差的均值，将这个均值作为泛化误差的估计。

### 留一交叉验证

留一法是$S=N$的$S$折交叉验证的特例，此时$S$等于样本数$m$,这样对于$m$个样本，每次选择$m-1$个样本来训练数据。由于训练集和初始数据集只少了一个样本，因此训练出来的模型与真是模型比较近似，因此留一法的评估结果往往比较准确。但是缺点是数据集比较大的时候计算量太大。





































