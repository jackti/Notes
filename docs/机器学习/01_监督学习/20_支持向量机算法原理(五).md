# 支持向量机算法原理(五)

SVM算法可以扩展到回归问题。

## SVM回归模型损失函数

在SVM分类模型中，目标函数是让$\frac{1}{2}||w||^2_2$最小，同时让各个训练集中的点尽量远离自己类别一边的支持向量，即$y^{(i)}(w\cdot \phi(x^{(i)})+b)\ge 1$。如果是加入一个松弛变量$\zeta_i\ge0$，则目标函数是

$$
    \frac{1}{2}||w||^2_2+C\sum_{i=1}^m\zeta_i
$$

对应的约束条件变成：

$$
    y^{(i)}(w\cdot\phi(x^{(i)})+b)\ge 1-\zeta_i
$$

在回归问题中，目标是让训练集中的每个点$(x^{(i)},y^{(i)})$ ，尽量拟合到一个线性模型

$$
y^{(i)}=w\cdot\phi(x^{(i)})+b
$$

优化的目标函数可以和SVM分类模型保持一致。定义一个常量$\epsilon\gt0$，对于某一个点$(x^{(i)},y^{(i)})$：

（1）如果$|y^{(i)}-w\cdot\phi(x^{(i)})-b|\le\epsilon$，则完全没有损失；

（2）如果$|y^{(i)}-w\cdot\phi(x^{(i)})-b|\gt \epsilon$，则对应的损失为：$|y^{(i)}-w\cdot\phi(x^{(i)})-b|- \epsilon$。

所以在SVM回归模型中的损失函数度量为：

$$
err(x^{(i)},y^{(i)})=\left\{
\begin{aligned}
    &0  &| y^{(i)}-w\cdot\phi(x^{(i)})-b|\le \epsilon \\
    &y^{(i)}-w\cdot\phi(x^{(i)})-b|- \epsilon  &|y^{(i)}-w\cdot\phi(x^{(i)})-b|\gt \epsilon
   \end{aligned}
\right.
$$




## SVM回归模型

SVM回归模型的目标函数如下：

$$
\min_{w,b} \frac{1}{2}||w||^2_2 \\
s.t.\;\;|y^{(i)}-w\cdot\phi(x^{(i)})-b|\le \epsilon  \\
$$

同样地，回归模型也可以对每个样本$(x^{(i)},y^{(i)})$加入松弛变量$\zeta_i\ge0$。在式(1)中约束模型是绝对值形式的，实际上有两个不等式，所以加入的松弛变量也需要两个$\zeta_i,\hat{\zeta_i}$。加入松弛变量后的损失函数变为：

$$
\min_{w,b}\frac{1}{2}||w||^2_2+C\sum_{i=1}^m(\zeta_i+\hat{\zeta_i})\\
s.t. \;\;  w\cdot\phi(x^{(i)})+b-y^{(i)}\le \epsilon +\zeta_i \\
\qquad y^{(i)}-w\cdot\phi(x^{(i)})-b\le \epsilon  +\hat{\zeta_i}\\
\qquad  \zeta_i\ge 0, \;  \hat{\zeta_i}\ge 0\qquad (i=1,2,...,m)
$$

引入拉格朗日乘子$\mu_i\ge0,\hat{\mu_i}\ge0,\alpha_i\ge0,\hat{\alpha_i}\ge0$，由拉格朗日乘子得到拉格朗日函数为：

$$
L(w,b,\alpha,\hat{\alpha},\zeta,\hat\zeta,\mu,\hat\mu)\\
=\frac{1}{2}||w||^2_2+C\sum_{i=1}^m(\zeta_i+\hat\zeta_i)-\sum_{i=1}^m\mu_i\zeta_i-\sum_{i=1}^m\hat\mu_i\hat\zeta_i\\
+\sum_{i=1}^m\alpha_i(f(x^{(i)})-y^{(i)}-\epsilon-\zeta_i)+\sum_{i=1}^m\hat\alpha_i(y^{(i)}-f(x^{(i)})-\epsilon-\hat\zeta_i)
$$

于是求解的目标变为：

$$
\min_{w,b,\zeta,\hat\zeta}\;\max_{\mu\ge0,\hat\mu\ge0,\alpha\ge0,\hat\alpha\ge0}L(w,b,\alpha,\hat{\alpha},\zeta,\hat\zeta,\mu,\hat\mu)
$$

可以通过拉格朗日对偶将优化问题转化为等价的对偶问题：

$$
\max_{\mu\ge0,\hat\mu\ge0,\alpha\ge0,\hat\alpha\ge0}\;\min_{w,b,\zeta,\hat\zeta}L(w,b,\alpha,\hat{\alpha},\zeta,\hat\zeta,\mu,\hat\mu)
$$

令$L(w,b,\alpha,\hat{\alpha},\zeta,\hat\zeta,\mu,\hat\mu)$对$w,b,\zeta,\hat\zeta$求偏导为零得到：

$$
\frac{\partial L}{\partial w}=0 \Rightarrow w=\sum_{i=1}^m(\hat\alpha_i-\alpha_i)\phi(x^{(i)})\\
\frac{\partial L}{\partial b}=0\Rightarrow 0=\sum_{i=1}^m(\hat\alpha_i-\alpha_i)\\
\frac{\partial L}{\partial \zeta_i}=0\Rightarrow  C=\alpha_i+\mu_i \\
\frac{\partial L}{\partial \hat\zeta_i}=0\Rightarrow C=\hat\alpha_i+\hat\mu_i \\
$$

将式(6)带入$L(w,b,\alpha,\hat{\alpha},\zeta,\hat\zeta,\mu,\hat\mu)$消去$w,b,\zeta,\hat\zeta$得到：

$$
\max_{\alpha,\hat\alpha} -\frac{1}{2}\sum_{i=1}^m\sum_{j=1}^m(\hat\alpha_i-\alpha_i)(\hat\alpha_j-\alpha_j)K(x^{(i)},x^{(j)})+\sum_{i=1}^m[ y^{(i)}(\hat\alpha_i-\alpha_i)-\epsilon(\hat\alpha_i+\alpha_i)]\\
s.t. \sum_{i=1}^m(\hat\alpha_i-\alpha_i)=0\\
0\le \alpha_i,\hat\alpha_i\le C
$$

上述过程中需满足KKT条件，即：

$$
\left\{
\begin{array}{}
\alpha_i(f(x^{(i)})-y^{(i)}-\epsilon-\zeta_i)=0\\
\hat\alpha_i(f(x^{(i)})-y^{(i)}-\epsilon-\hat\zeta_i)=0\\
\alpha_i\hat\alpha_i=0,\quad \zeta_i\hat\zeta_i=0\\
(C-\alpha_i)\zeta_i=0,\quad (C-\hat\alpha_i)\hat\zeta_i=0
\end{array}
\right.
$$

则SVR的解形如：

$$
\begin{align}
w&=\sum_{i=1}^m(\hat\alpha_i-\alpha_i)\phi(x^{(i)})\\
f(x)&=\sum_{i=1}^m(\hat\alpha_i-\alpha_i)K(x,x^{(i)})+b
\end{align}
$$






































